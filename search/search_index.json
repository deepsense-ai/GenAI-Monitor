{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GenAI Monitor","text":"GenAI Monitor <p> Observability for Generative AI </p>"},{"location":"#overview","title":"Overview","text":"<p>GenAI Monitor provides robust observability tools for Generative AI applications with zero additional effort. Simply import the library, and it automatically monitors, tracks, and analyzes your AI model's inputs, outputs, and performance in production environments - no code changes required to your existing AI workflows.</p> <p>The library seamlessly integrates with popular AI frameworks and automatically captures model calls, stores responses for later retrieval without requiring you to modify your application code.</p>"},{"location":"#features","title":"Features","text":"<ul> <li> <p>Implicit Observability for Popular Frameworks: Works out-of-the-box with most popular frameworks and providers without any code changes: Transformers, Diffusers, OpenAI, LiteLLM</p> </li> <li> <p>Persistent Data Storage &amp; Retrieval: Store model inputs and outputs so identical calls can be retrieved from the database without re-running expensive and time consuming model inference.</p> </li> <li> <p>Custom Function &amp; Method Registration: Easily extend monitoring to any GenAI tool. The flexible registration system allows you to monitor any Python function or method with minimal configuration.</p> </li> <li> <p>Artifact Tracking: Attach metadata and artifacts to model calls for comprehensive traceability.</p> </li> <li>Modular Installation: Install only what you need to keep your dependencies lean.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>To start tracking your GenAI models, install the <code>genai-monitor</code> package:</p> <pre><code>pip install genai-monitor\n</code></pre> <p>Install with support for specific frameworks:</p> <pre><code># HuggingFace Transformers\npip install genai-monitor[transformers]\n\n# Diffusers\npip install genai-monitor[diffusers]\n\n# OpenAI\npip install genai-monitor[openai]\n\n# LiteLLM\npip install genai-monitor[litellm]\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<p>GenAI Monitor automatically intercepts calls to supported frameworks. When you make the second API call with identical parameters, GenAI Monitor retrieves the cached response directly from the database instead of sending another request to OpenAI - saving time, reducing costs, and decreasing latency. This all happens transparently without any changes to your application code - simply import the library and it works!</p> <pre><code>import os\n\n# Import genai_monitor.auto to automatically enable monitoring\n# for supported frameworks with zero code changes\nimport genai_monitor.auto\nfrom openai import OpenAI\n\napi_key = os.getenv(\"OPENAI_API_KEY\")\nclient = OpenAI(api_key=api_key)\nquestion = \"How hard is to create a monitoring framework for GenAI models?\"\n\n# First API call - This request is sent to OpenAI and the result is stored in the database\nresponse = client.chat.completions.create(\n    messages=[{\"role\": \"user\", \"content\": question}],\n    model=\"gpt-4o-mini-2024-07-18\",\n    max_tokens=400,\n    temperature=0.4,\n)\nprint(response.choices[0].message.content)\n\n# Second API call with identical parameters -\n# NO request is sent to OpenAI! Instead, the result is retrieved from the local database\nresponse = client.chat.completions.create(\n    messages=[{\"role\": \"user\", \"content\": question}],\n    model=\"gpt-4o-mini-2024-07-18\",\n    max_tokens=400,\n    temperature=0.4,\n)\nprint(response.choices[0].message.content)\n# The application code remains unchanged, but you save time and API costs\n</code></pre>"},{"location":"#future-work","title":"Future Work","text":"<p>GenAI Monitor is under active development. Here are some of the exciting features on our roadmap:</p> <ul> <li> Expanded Cloud Provider Integration</li> <li> Vector Database Integration</li> <li> Extensive Query Language</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Quickstart</li> <li>How-to guides</li> <li>API reference</li> </ul>"},{"location":"api_reference/db/","title":"Database","text":""},{"location":"api_reference/db/#sessionmanager","title":"SessionManager","text":""},{"location":"api_reference/db/#genai_monitor.db.config.SessionManager","title":"genai_monitor.db.config.SessionManager","text":"<pre><code>SessionManager(database_url: str = DEFAULT_DATABASE_URL)\n</code></pre> <p>Manages the database engine and provides session management.</p> Source code in <code>src/genai_monitor/db/config.py</code> <pre><code>def __init__(self, database_url: str = DEFAULT_DATABASE_URL):  # noqa: ANN204,D107\n    self.initialize(database_url=database_url)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.config.SessionManager.initialize","title":"initialize","text":"<pre><code>initialize(\n    database_url: str = DEFAULT_DATABASE_URL,\n) -&gt; SessionManager\n</code></pre> <p>Initializes the database engine and session factory. This should be called once on application start.</p> PARAMETER DESCRIPTION <code>database_url</code> <p>The URL for the database connection. Defaults to sqlite:///genai_eval.db.</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_DATABASE_URL</code> </p> RETURNS DESCRIPTION <code>SessionManager</code> <p>The <code>SessionManager</code> object.</p> Source code in <code>src/genai_monitor/db/config.py</code> <pre><code>def initialize(self, database_url: str = DEFAULT_DATABASE_URL) -&gt; \"SessionManager\":\n    \"\"\"Initializes the database engine and session factory. This should be called once on application start.\n\n    Args:\n        database_url: The URL for the database connection. Defaults to sqlite:///genai_eval.db.\n\n    Returns:\n        The `SessionManager` object.\n    \"\"\"\n    if self._engine is None:\n        self._engine = create_engine(database_url)\n        self._session_factory = sessionmaker(bind=self._engine, expire_on_commit=False)\n        BaseModel.metadata.create_all(bind=self._engine)\n\n    return self\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.config.SessionManager.session_scope","title":"session_scope","text":"<pre><code>session_scope() -&gt; Generator[Session, None, None]\n</code></pre> <p>Provide a transactional scope around a series of operations. Commits or rolls back on error.</p> RAISES DESCRIPTION <code>Exception</code> <p>on any error during database transaction</p> <code>ConnectionError</code> <p>if the database connection has not been initialized yet</p> YIELDS DESCRIPTION <code>Session</code> <p>The database connection session</p> Source code in <code>src/genai_monitor/db/config.py</code> <pre><code>@contextmanager\ndef session_scope(self) -&gt; Generator[Session, None, None]:\n    \"\"\"Provide a transactional scope around a series of operations. Commits or rolls back on error.\n\n    Raises:\n        Exception: on any error during database transaction\n        ConnectionError: if the database connection has not been initialized yet\n\n    Yields:\n        The database connection session\n    \"\"\"\n    if self._session_factory is None:\n        raise ConnectionError(\n            \"The connection to the database must be initialized through, SessionManager.initialize()\"\n        )\n\n    session = self._session_factory(expire_on_commit=False)\n    try:\n        yield session\n        session.commit()\n    except Exception:\n        session.rollback()\n        raise\n    finally:\n        session.close()\n</code></pre>"},{"location":"api_reference/db/#database-manager","title":"Database Manager","text":""},{"location":"api_reference/db/#genai_monitor.db.manager.DBManager","title":"genai_monitor.db.manager.DBManager","text":"<p>A database manager class.</p> <p>Class provides basic operations for saving, updating and searching records in the database using SQLAlchemy ORM models.</p>"},{"location":"api_reference/db/#genai_monitor.db.manager.DBManager.session_manager","title":"session_manager  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>session_manager: Optional[SessionManager] = None\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.manager.DBManager.save","title":"save","text":"<pre><code>save(instance: BaseModel) -&gt; BaseModel\n</code></pre> <p>Saves an instance of a model to the database.</p> PARAMETER DESCRIPTION <code>instance</code> <p>The ORM model instance to be saved.</p> <p> TYPE: <code>BaseModel</code> </p> RETURNS DESCRIPTION <code>BaseModel</code> <p>The saved ORM model instance.</p> Source code in <code>src/genai_monitor/db/manager.py</code> <pre><code>def save(self, instance: BaseModel) -&gt; BaseModel:\n    \"\"\"Saves an instance of a model to the database.\n\n    Args:\n        instance: The ORM model instance to be saved.\n\n    Returns:\n        The saved ORM model instance.\n    \"\"\"\n    with self.session_manager.session_scope() as session:\n        session.add(instance)\n        session.commit()\n        self._eager_load_instance_relations(instance=instance)\n        return instance\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.manager.DBManager.search","title":"search","text":"<pre><code>search(\n    model: Type[BaseModel],\n    filters: Optional[Dict[str, Any]] = None,\n) -&gt; Sequence[Row]\n</code></pre> <p>Searches for records in the database that match the given filters.</p> PARAMETER DESCRIPTION <code>model</code> <p>The ORM model class representing the database table to search.</p> <p> TYPE: <code>Type[BaseModel]</code> </p> <code>filters</code> <p>Dictionary of filter criteria to locate specific records.</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Sequence[Row]</code> <p>A sequence of rows matching the filter criteria.</p> Source code in <code>src/genai_monitor/db/manager.py</code> <pre><code>def search(self, model: Type[BaseModel], filters: Optional[Dict[str, Any]] = None) -&gt; Sequence[Row]:\n    \"\"\"Searches for records in the database that match the given filters.\n\n    Args:\n        model: The ORM model class representing the database table to search.\n        filters: Dictionary of filter criteria to locate specific records.\n\n    Returns:\n        A sequence of rows matching the filter criteria.\n    \"\"\"\n    with self.session_manager.session_scope() as session:\n        query = session.query(model)\n        if filters:\n            query = query.filter_by(**filters)\n        result = query.all()\n        for instance in result:\n            self._eager_load_instance_relations(instance)\n        return result\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.manager.DBManager.update","title":"update","text":"<pre><code>update(\n    instance: Optional[BaseModel] = None,\n    model: Optional[Type[BaseModel]] = None,\n    filters: Optional[Dict[str, Any]] = None,\n    values: Optional[Dict[str, Any]] = None,\n) -&gt; Union[BaseModel, Sequence[Row]]\n</code></pre> <p>Updates records in the database.</p> <p>If an instance is provided, it will be updated directly. Otherwise, model and filter criteria are used to locate records for updating.</p> PARAMETER DESCRIPTION <code>instance</code> <p>An existing ORM model instance to update.</p> <p> TYPE: <code>Optional[BaseModel]</code> DEFAULT: <code>None</code> </p> <code>model</code> <p>The ORM model class representing the table to update.</p> <p> TYPE: <code>Optional[Type[BaseModel]]</code> DEFAULT: <code>None</code> </p> <code>filters</code> <p>Dictionary of filter criteria to locate records to update.</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p> <code>values</code> <p>Dictionary of field names and values to update.</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Union[BaseModel, Sequence[Row]]</code> <p>The updated instance if <code>instance</code> was provided or the updated DB rows.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If neither <code>instance</code> nor <code>model</code> is provided.</p> Source code in <code>src/genai_monitor/db/manager.py</code> <pre><code>def update(\n    self,\n    instance: Optional[BaseModel] = None,\n    model: Optional[Type[BaseModel]] = None,\n    filters: Optional[Dict[str, Any]] = None,\n    values: Optional[Dict[str, Any]] = None,\n) -&gt; Union[BaseModel, Sequence[Row]]:\n    \"\"\"Updates records in the database.\n\n    If an instance is provided, it will be updated\n    directly. Otherwise, model and filter criteria are used to locate records for updating.\n\n    Args:\n        instance: An existing ORM model instance to update.\n        model: The ORM model class representing the table to update.\n        filters: Dictionary of filter criteria to locate records to update.\n        values: Dictionary of field names and values to update.\n\n    Returns:\n       The updated instance if `instance` was provided or the updated DB rows.\n\n    Raises:\n        ValueError: If neither `instance` nor `model` is provided.\n    \"\"\"\n    if (instance is None) and (model is None):\n        raise ValueError(\n            \"To update DB resource provide either an instance of the ORM class or an ORM model with filters.\"\n        )\n\n    if (instance is not None) and (model is not None):\n        logger.warning(\n            \"Provided both instance of an ORM class and the ORM model for update, instance will be used.\"\n        )\n\n    with self.session_manager.session_scope() as session:\n        if instance is not None:\n            for field_name, field_value in values.items():  # type: ignore\n                setattr(instance, field_name, field_value)\n            session.add(instance)\n            session.commit()\n            return instance\n\n        query = session.query(model).filter_by(**filters)\n        query_results = query.all()\n        for result in query_results:\n            for field_name, field_value in values.items():  # type: ignore\n                setattr(result, field_name, field_value)\n        session.commit()\n        for result in query_results:\n            self._eager_load_instance_relations(result)\n        return query_results\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.manager.DBManager.join_search","title":"join_search","text":"<pre><code>join_search(\n    target_model: Type[BaseModel],\n    join_model: Type[BaseModel],\n    on_condition: Any,\n    target_filters: Optional[Dict[str, Any]] = None,\n    join_filters: Optional[Dict[str, Any]] = None,\n) -&gt; Sequence[Row]\n</code></pre> <p>Performs a join search between two models based on a join condition and optional filters.</p> PARAMETER DESCRIPTION <code>target_model</code> <p>The ORM model class representing the primary table to search.</p> <p> TYPE: <code>Type[BaseModel]</code> </p> <code>join_model</code> <p>The ORM model class representing the table to join with.</p> <p> TYPE: <code>Type[BaseModel]</code> </p> <code>on_condition</code> <p>The join condition specifying how to link the two tables.</p> <p> TYPE: <code>Any</code> </p> <code>target_filters</code> <p>Dictionary of filter criteria for the target model.</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p> <code>join_filters</code> <p>Dictionary of filter criteria for the join model.</p> <p> TYPE: <code>Optional[Dict[str, Any]]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Sequence[Row]</code> <p>A sequence of rows resulting from the join search, filtered as specified.</p> Source code in <code>src/genai_monitor/db/manager.py</code> <pre><code>def join_search(\n    self,\n    target_model: Type[BaseModel],\n    join_model: Type[BaseModel],\n    on_condition: Any,\n    target_filters: Optional[Dict[str, Any]] = None,\n    join_filters: Optional[Dict[str, Any]] = None,\n) -&gt; Sequence[Row]:\n    \"\"\"Performs a join search between two models based on a join condition and optional filters.\n\n    Args:\n        target_model: The ORM model class representing the primary table to search.\n        join_model: The ORM model class representing the table to join with.\n        on_condition: The join condition specifying how to link the two tables.\n        target_filters: Dictionary of filter criteria for the target model.\n        join_filters: Dictionary of filter criteria for the join model.\n\n    Returns:\n        A sequence of rows resulting from the join search, filtered as specified.\n    \"\"\"\n    with self.session_manager.session_scope() as session:\n        query = session.query(target_model).join(join_model, on_condition)\n\n        if target_filters:\n            target_conditions = [getattr(target_model, key) == value for key, value in target_filters.items()]\n            query = query.filter(and_(*target_conditions))\n\n        if join_filters:\n            join_conditions = [getattr(join_model, key) == value for key, value in join_filters.items()]\n            query = query.filter(and_(*join_conditions))\n\n        results = query.all()\n        return results\n</code></pre>"},{"location":"api_reference/db/#tables","title":"Tables","text":""},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConditioningTable","title":"genai_monitor.db.schemas.tables.ConditioningTable","text":"<p>               Bases: <code>BaseModel</code></p> <p>Database table representing the value of conditioning.</p>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConditioningTable.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id: Mapped[int] = mapped_column(\n    primary_key=True, autoincrement=True\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConditioningTable.type_id","title":"type_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type_id: Mapped[Optional[str]] = mapped_column(\n    ForeignKey(\"conditioning_type.id\")\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConditioningTable.value","title":"value  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>value: Mapped[dict] = mapped_column(JSON)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConditioningTable.hash","title":"hash  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>hash: Mapped[str] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConditioningTable.value_metadata","title":"value_metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>value_metadata: Mapped[Optional[dict]] = mapped_column(JSON)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConditioningTable.samples","title":"samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>samples: Mapped[List[SampleTable]] = relationship(\n    back_populates=\"conditioning\"\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConditioningTypeTable","title":"genai_monitor.db.schemas.tables.ConditioningTypeTable","text":"<p>               Bases: <code>BaseModel</code></p> <p>Database table representing the type of conditioning.</p>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConditioningTypeTable.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id: Mapped[int] = mapped_column(\n    primary_key=True, autoincrement=True\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConditioningTypeTable.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type: Mapped[str] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable","title":"genai_monitor.db.schemas.tables.SampleTable","text":"<p>               Bases: <code>BaseModel</code></p> <p>Database table representing the sample - an atomic unit of data in the system.</p>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id: Mapped[int] = mapped_column(\n    primary_key=True, autoincrement=True\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.model_id","title":"model_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_id: Mapped[Optional[int]] = mapped_column(\n    ForeignKey(\"model.id\")\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.conditioning_id","title":"conditioning_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>conditioning_id: Mapped[Optional[int]] = mapped_column(\n    ForeignKey(\"conditioning.id\")\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.user_id","title":"user_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>user_id: Mapped[Optional[int]] = mapped_column(\n    ForeignKey(\"user.id\")\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: Mapped[Optional[str]] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.hash","title":"hash  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>hash: Mapped[str] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.meta","title":"meta  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>meta: Mapped[Optional[dict]] = mapped_column(JSON)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.generation_id","title":"generation_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>generation_id: Mapped[Optional[int]] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.status","title":"status  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status: Mapped[str] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.version","title":"version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>version: Mapped[str] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.conditioning","title":"conditioning  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>conditioning: Mapped[ConditioningTable] = relationship(\n    back_populates=\"samples\"\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.user","title":"user  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>user: Mapped[UserTable] = relationship(\n    back_populates=\"samples\"\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.SampleTable.artifacts","title":"artifacts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>artifacts: Mapped[List[ArtifactTable]] = relationship(\n    back_populates=\"sample\"\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ModelTable","title":"genai_monitor.db.schemas.tables.ModelTable","text":"<p>               Bases: <code>BaseModel</code></p> <p>Database table representing the generative model.</p>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ModelTable.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id: Mapped[int] = mapped_column(\n    primary_key=True, autoincrement=True\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ModelTable.hash","title":"hash  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>hash: Mapped[Optional[str]] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ModelTable.model_class","title":"model_class  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_class: Mapped[Optional[str]] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ModelTable.checkpoint_location","title":"checkpoint_location  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>checkpoint_location: Mapped[Optional[str]] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ModelTable.checkpoint_metadata","title":"checkpoint_metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>checkpoint_metadata: Mapped[Optional[dict]] = mapped_column(\n    JSON\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ModelTable.training_step","title":"training_step  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>training_step: Mapped[Optional[int]] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ModelTable.model_metadata","title":"model_metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_metadata: Mapped[Optional[dict]] = mapped_column(JSON)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConfigurationTable","title":"genai_monitor.db.schemas.tables.ConfigurationTable","text":"<p>               Bases: <code>BaseModel</code></p> <p>Database table representing system configuration.</p> <p>Default values are set at the database level to ensure consistency across all instances.</p>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConfigurationTable.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id: Mapped[int] = mapped_column(\n    primary_key=True, autoincrement=True\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConfigurationTable.key","title":"key  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>key: Mapped[str] = mapped_column(unique=True)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConfigurationTable.value","title":"value  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>value: Mapped[str] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConfigurationTable.description","title":"description  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>description: Mapped[Optional[str]] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConfigurationTable.updated_at","title":"updated_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>updated_at: Mapped[str] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConfigurationTable.is_default","title":"is_default  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>is_default: Mapped[bool] = mapped_column(\n    server_default=text(\"0\")\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ConfigurationTable.default_value","title":"default_value  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_value: Mapped[Optional[str]] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.UserTable","title":"genai_monitor.db.schemas.tables.UserTable","text":"<p>               Bases: <code>BaseModel</code></p> <p>Database table representing the users.</p>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.UserTable.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id: Mapped[int] = mapped_column(\n    primary_key=True, autoincrement=True\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.UserTable.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: Mapped[str] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.UserTable.hash","title":"hash  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>hash: Mapped[str] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.UserTable.samples","title":"samples  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>samples: Mapped[List[SampleTable]] = relationship(\n    back_populates=\"user\"\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ArtifactTable","title":"genai_monitor.db.schemas.tables.ArtifactTable","text":"<p>               Bases: <code>BaseModel</code></p> <p>Database table representing the artifact - an atomic unit of data in the system.</p>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ArtifactTable.id","title":"id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>id: Mapped[int] = mapped_column(\n    primary_key=True, autoincrement=True\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ArtifactTable.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: Mapped[str] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ArtifactTable.value","title":"value  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>value: Mapped[Optional[str]] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ArtifactTable.hash","title":"hash  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>hash: Mapped[str] = mapped_column()\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ArtifactTable.sample_id","title":"sample_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sample_id: Mapped[int] = mapped_column(\n    ForeignKey(\"sample.id\")\n)\n</code></pre>"},{"location":"api_reference/db/#genai_monitor.db.schemas.tables.ArtifactTable.sample","title":"sample  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sample: Mapped[SampleTable] = relationship(\n    back_populates=\"artifacts\"\n)\n</code></pre>"},{"location":"api_reference/injectors/","title":"Dependency injection","text":""},{"location":"api_reference/injectors/#dependency-container","title":"Dependency Container","text":""},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer","title":"genai_monitor.injectors.containers.DependencyContainer","text":"<p>               Bases: <code>DeclarativeContainer</code></p> <p>Dependency container for the application.</p>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.config","title":"config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>config = Configuration()\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.wrapper_factory","title":"wrapper_factory  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>wrapper_factory = Singleton(provides=WrapperFactory)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.wrapper_registry","title":"wrapper_registry  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>wrapper_registry = Singleton(\n    provides=WrapperRegistry,\n    wrapper_factory=wrapper_factory,\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.session_manager","title":"session_manager  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>session_manager = Factory(\n    provides=SessionManager, database_url=url\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.db_manager","title":"db_manager  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>db_manager = Factory(\n    provides=DBManager, session_manager=session_manager\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.persistency_manager","title":"persistency_manager  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>persistency_manager = Singleton(\n    provides=PersistencyManager, path=path, enabled=enabled\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.runtime_manager","title":"runtime_manager  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>runtime_manager = Singleton(provides=RuntimeManager)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.artifact_wrapper_factory","title":"artifact_wrapper_factory  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>artifact_wrapper_factory = Singleton(\n    provides=ArtifactWrapperFactory\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.artifact_registry","title":"artifact_registry  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>artifact_registry = Singleton(\n    provides=ArtifactRegistry,\n    artifact_wrapper_factory=artifact_wrapper_factory,\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.default_hashing_function","title":"default_hashing_function  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>default_hashing_function = Object(\n    provides=default_model_hashing_function\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.transformers_output_parser","title":"transformers_output_parser  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>transformers_output_parser = Factory(\n    provides=TransformersTextGenerationParser\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.transformers_conditioning_parser","title":"transformers_conditioning_parser  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>transformers_conditioning_parser = Factory(\n    TransformersTextGenerationConditioningParser\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.transformers_hashing_function","title":"transformers_hashing_function  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>transformers_hashing_function = Object(\n    provides=get_transformers_model_hash\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.transformers_json_path","title":"transformers_json_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>transformers_json_path = Factory(\n    get_absolute_path,\n    _TRANSFORMERS_JSON_PATH,\n    relative_to=abspath(__file__),\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.transformers_class_def_collection","title":"transformers_class_def_collection  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>transformers_class_def_collection = Factory(\n    from_json, json_path=transformers_json_path\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.register_transformers","title":"register_transformers  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>register_transformers = Callable(\n    register_class_collection,\n    definition_collection=transformers_class_def_collection,\n    registry=wrapper_registry,\n    db_manager=db_manager,\n    persistency_manager=persistency_manager,\n    runtime_manager=runtime_manager,\n    output_parser=transformers_output_parser,\n    conditioning_parser=transformers_conditioning_parser,\n    hashing_function=transformers_hashing_function,\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.openai_output_parser","title":"openai_output_parser  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>openai_output_parser = Factory(\n    provides=OpenAIChatOutputParser\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.openai_conditioning_parser","title":"openai_conditioning_parser  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>openai_conditioning_parser = Factory(\n    OpenAIConditioningParser\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.empty_model_hash","title":"empty_model_hash  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>empty_model_hash = Object(get_empty_model_hash)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.providers_json_path","title":"providers_json_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>providers_json_path = Factory(\n    get_absolute_path,\n    _PROVIDERS_JSON_PATH,\n    relative_to=abspath(__file__),\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.providers_class_def_collection","title":"providers_class_def_collection  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>providers_class_def_collection = Factory(\n    from_json, json_path=providers_json_path\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.register_providers","title":"register_providers  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>register_providers = Callable(\n    register_class_collection,\n    definition_collection=providers_class_def_collection,\n    registry=wrapper_registry,\n    db_manager=db_manager,\n    persistency_manager=persistency_manager,\n    runtime_manager=runtime_manager,\n    output_parser=openai_output_parser,\n    conditioning_parser=openai_conditioning_parser,\n    hashing_function=empty_model_hash,\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.diffusers_output_parser","title":"diffusers_output_parser  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>diffusers_output_parser = Factory(\n    provides=StableDiffusionOutputParser\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.diffusers_conditioning_parser","title":"diffusers_conditioning_parser  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>diffusers_conditioning_parser = Factory(\n    StableDiffusionConditioningParser\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.diffusers_hashing_function","title":"diffusers_hashing_function  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>diffusers_hashing_function = Object(\n    provides=get_diffusers_model_hash\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.diffusers_json_path","title":"diffusers_json_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>diffusers_json_path = Factory(\n    get_absolute_path,\n    _DIFFUSERS_JSON_PATH,\n    relative_to=abspath(__file__),\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.diffusers_class_def_collection","title":"diffusers_class_def_collection  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>diffusers_class_def_collection = Factory(\n    from_json, json_path=diffusers_json_path\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.register_diffusers","title":"register_diffusers  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>register_diffusers = Callable(\n    register_class_collection,\n    definition_collection=diffusers_class_def_collection,\n    registry=wrapper_registry,\n    db_manager=db_manager,\n    persistency_manager=persistency_manager,\n    runtime_manager=runtime_manager,\n    output_parser=diffusers_output_parser,\n    conditioning_parser=diffusers_conditioning_parser,\n    hashing_function=diffusers_hashing_function,\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.litellm_output_parser","title":"litellm_output_parser  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>litellm_output_parser = Factory(\n    provides=LiteLLMCompletionOutputParser\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.litellm_conditioning_parser","title":"litellm_conditioning_parser  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>litellm_conditioning_parser = Factory(\n    provides=LiteLLMCompletionConditioningParser\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.litellm_json_path","title":"litellm_json_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>litellm_json_path = Factory(\n    get_absolute_path,\n    _LITELLM_JSON_PATH,\n    relative_to=abspath(__file__),\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.litellm_def_collection","title":"litellm_def_collection  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>litellm_def_collection = Factory(\n    from_json, json_path=litellm_json_path\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.DependencyContainer.register_litellm","title":"register_litellm  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>register_litellm = Callable(\n    register_function_collection,\n    definition_collection=litellm_def_collection,\n    registry=wrapper_registry,\n    db_manager=db_manager,\n    persistency_manager=persistency_manager,\n    runtime_manager=runtime_manager,\n    output_parser=litellm_output_parser,\n    conditioning_parser=litellm_conditioning_parser,\n    hashing_function=get_function_full_path,\n)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.containers.get_container","title":"genai_monitor.injectors.containers.get_container","text":"<pre><code>get_container() -&gt; DependencyContainer\n</code></pre> <p>Get the dependency container.</p> RETURNS DESCRIPTION <code>DependencyContainer</code> <p>The dependency container.</p> Source code in <code>src/genai_monitor/injectors/containers.py</code> <pre><code>def get_container() -&gt; DependencyContainer:\n    \"\"\"Get the dependency container.\n\n    Returns:\n        The dependency container.\n    \"\"\"\n    global _container  # noqa: PLW0603\n    if _container is None:\n        _container = DependencyContainer()\n    return _container\n</code></pre>"},{"location":"api_reference/injectors/#registry","title":"Registry","text":""},{"location":"api_reference/injectors/#genai_monitor.injectors.registry.WrapperRegistry","title":"genai_monitor.injectors.registry.WrapperRegistry","text":"<p>Registry for function wrappers.</p> <p>This class is responsible for registering and unregistering wrappers.</p> ATTRIBUTE DESCRIPTION <code>_wrapper_factory</code> <p>Factory for creating wrappers.</p> <p> TYPE: <code>WrapperFactory</code> </p> <code>_registry</code> <p>Dictionary of registered wrappers.</p> <p> TYPE: <code>Dict[str, Union[FunctionWrapper, MethodWrapper]]</code> </p>"},{"location":"api_reference/injectors/#genai_monitor.injectors.registry.WrapperRegistry.register","title":"register","text":"<pre><code>register(\n    func: Callable,\n    db_manager: DBManager,\n    persistency_manager: PersistencyManager,\n    runtime_manager: RuntimeManager,\n    output_parser: BaseModelOutputParser,\n    conditioning_parser: BaseConditioningParser,\n    hashing_function: Callable[[Any], str],\n    max_unique_instances: int = 1,\n)\n</code></pre> <p>Register a function with the registry.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function or method to register.</p> <p> TYPE: <code>Callable</code> </p> <code>db_manager</code> <p>The database manager.</p> <p> TYPE: <code>DBManager</code> </p> <code>persistency_manager</code> <p>The persistency manager.</p> <p> TYPE: <code>PersistencyManager</code> </p> <code>runtime_manager</code> <p>The runtime manager.</p> <p> TYPE: <code>RuntimeManager</code> </p> <code>output_parser</code> <p>The output parser.</p> <p> TYPE: <code>BaseModelOutputParser</code> </p> <code>conditioning_parser</code> <p>The conditioning parser.</p> <p> TYPE: <code>BaseConditioningParser</code> </p> <code>hashing_function</code> <p>The hashing function.</p> <p> TYPE: <code>Callable[[Any], str]</code> </p> <code>max_unique_instances</code> <p>The maximum number of unique sample instances for each conditioning.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> Source code in <code>src/genai_monitor/injectors/registry.py</code> <pre><code>def register(  # noqa: PLR0913\n    self,\n    func: Callable,\n    db_manager: DBManager,\n    persistency_manager: PersistencyManager,\n    runtime_manager: RuntimeManager,\n    output_parser: BaseModelOutputParser,\n    conditioning_parser: BaseConditioningParser,\n    hashing_function: Callable[[Any], str],\n    max_unique_instances: int = 1,\n):\n    \"\"\"Register a function with the registry.\n\n    Args:\n        func: The function or method to register.\n        db_manager: The database manager.\n        persistency_manager: The persistency manager.\n        runtime_manager: The runtime manager.\n        output_parser: The output parser.\n        conditioning_parser: The conditioning parser.\n        hashing_function: The hashing function.\n        max_unique_instances: The maximum number of unique sample instances for each conditioning.\n    \"\"\"\n    func_name = func.__qualname__\n\n    if func_name in self._registry:\n        logger.warning(f\"Overriding function {func_name}, which is already registered.\")\n\n    wrapper = self._wrapper_factory.create(\n        func=func,\n        db_manager=db_manager,\n        persistency_manager=persistency_manager,\n        runtime_manager=runtime_manager,\n        output_parser=output_parser,\n        conditioning_parser=conditioning_parser,\n        hashing_function=hashing_function,\n        max_unique_instances=max_unique_instances,\n    )\n    self._registry[func_name] = wrapper\n    func_wrapped = wrapper.wrap(func=func)\n    override_func_in_module(func=func, func_override=func_wrapped)\n    override_func_in_imported_modules(func=func, func_override=func_wrapped)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.registry.WrapperRegistry.unregister","title":"unregister","text":"<pre><code>unregister(func: Callable)\n</code></pre> <p>Unregister a function from the registry.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function to unregister.</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>src/genai_monitor/injectors/registry.py</code> <pre><code>def unregister(self, func: Callable):\n    \"\"\"Unregister a function from the registry.\n\n    Args:\n        func: The function to unregister.\n    \"\"\"\n    func_name = func.__qualname__\n    wrapper = self._registry.pop(func_name, None)\n    if wrapper is None:\n        logger.warning(f\"Function {func_name} can't be unregistered as it doesn't exist in the registry.\")\n        return\n    override_func_in_module(func=func, func_override=wrapper.func)\n    override_func_in_imported_modules(func=func, func_override=wrapper.func)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.registry.WrapperRegistry.get_registered_list","title":"get_registered_list","text":"<pre><code>get_registered_list() -&gt; List[str]\n</code></pre> <p>Get a list of registered functions.</p> RETURNS DESCRIPTION <code>List[str]</code> <p>A list of registered functions.</p> Source code in <code>src/genai_monitor/injectors/registry.py</code> <pre><code>def get_registered_list(self) -&gt; List[str]:\n    \"\"\"Get a list of registered functions.\n\n    Returns:\n        A list of registered functions.\n    \"\"\"\n    return list(self._registry.keys())\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.registry.ArtifactRegistry","title":"genai_monitor.injectors.registry.ArtifactRegistry","text":"<p>Artifact registry.</p> ATTRIBUTE DESCRIPTION <code>_artifact_wrapper_factory</code> <p>Factory for creating artifact wrappers.</p> <p> TYPE: <code>ArtifactWrapperFactory</code> </p> <code>_registry</code> <p>Dictionary of registered artifacts (both forward and backward tracking).</p> <p> TYPE: <code>Dict[str, Dict[str, Union[ArtifactFunctionWrapper, ArtifactMethodWrapper]]]</code> </p>"},{"location":"api_reference/injectors/#genai_monitor.injectors.registry.ArtifactRegistry.register","title":"register","text":"<pre><code>register(\n    func: Callable,\n    direction: str,\n    db_manager: DBManager,\n    persistency_manager: PersistencyManager,\n    runtime_manager: RuntimeManager,\n)\n</code></pre> <p>Registers an artifact function or method.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function or method to register.</p> <p> TYPE: <code>Callable</code> </p> <code>direction</code> <p>The direction of the artifact (either 'forward' or 'backward').</p> <p> TYPE: <code>str</code> </p> <code>db_manager</code> <p>The database manager.</p> <p> TYPE: <code>DBManager</code> </p> <code>persistency_manager</code> <p>The persistency manager.</p> <p> TYPE: <code>PersistencyManager</code> </p> <code>runtime_manager</code> <p>The runtime manager.</p> <p> TYPE: <code>RuntimeManager</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the direction is not 'forward' or 'backward'.</p> Source code in <code>src/genai_monitor/injectors/registry.py</code> <pre><code>def register(\n    self,\n    func: Callable,\n    direction: str,\n    db_manager: DBManager,\n    persistency_manager: PersistencyManager,\n    runtime_manager: RuntimeManager,\n):\n    \"\"\"Registers an artifact function or method.\n\n    Args:\n        func: The function or method to register.\n        direction: The direction of the artifact (either 'forward' or 'backward').\n        db_manager: The database manager.\n        persistency_manager: The persistency manager.\n        runtime_manager: The runtime manager.\n\n    Raises:\n        ValueError: If the direction is not 'forward' or 'backward'.\n    \"\"\"\n    func_name = func.__qualname__\n\n    if func_name in self._registry[direction]:\n        logger.warning(f\"Overriding artifact {func_name}, which is already registered.\")\n\n    wrapper = self._artifact_wrapper_factory.create(\n        func=func, db_manager=db_manager, persistency_manager=persistency_manager, runtime_manager=runtime_manager\n    )\n    if direction == \"backward\":\n        func_wrapped = wrapper.wrap_backward(func=func)\n\n    elif direction == \"forward\":\n        func_wrapped = wrapper.wrap_forward(func=func)\n\n    else:\n        raise ValueError(f\"Invalid direction: {direction} (must be 'forward' or 'backward').\")\n\n    self._registry[direction][func_name] = wrapper\n\n    override_func_in_module(func=func, func_override=func_wrapped)\n    override_func_in_imported_modules(func=func, func_override=func_wrapped)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.registry.ArtifactRegistry.unregister","title":"unregister","text":"<pre><code>unregister(func: Callable, direction: str)\n</code></pre> <p>Removes an artifact function or method from the registry.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function or method to unregister.</p> <p> TYPE: <code>Callable</code> </p> <code>direction</code> <p>The direction of the artifact (either 'forward' or 'backward').</p> <p> TYPE: <code>str</code> </p> Source code in <code>src/genai_monitor/injectors/registry.py</code> <pre><code>def unregister(self, func: Callable, direction: str):\n    \"\"\"Removes an artifact function or method from the registry.\n\n    Args:\n        func: The function or method to unregister.\n        direction: The direction of the artifact (either 'forward' or 'backward').\n    \"\"\"\n    func_name = func.__qualname__\n    wrapper = self._registry[direction].pop(func_name, None)\n\n    if wrapper is None:\n        logger.warning(f\"Artifact {func_name} can't be unregistered as it doesn't exist in the registry.\")\n        return\n    override_func_in_module(func=func, func_override=wrapper.func)\n    override_func_in_imported_modules(func=func, func_override=wrapper.func)\n</code></pre>"},{"location":"api_reference/injectors/#wrappers","title":"Wrappers","text":""},{"location":"api_reference/injectors/#inference","title":"Inference","text":""},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper","title":"genai_monitor.injectors.wrapper.MethodWrapper","text":"<p>               Bases: <code>Wrapper</code></p> <p>Wrapper for class methods.</p>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper.db_manager","title":"db_manager  <code>instance-attribute</code>","text":"<pre><code>db_manager: DBManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper.persistency_manager","title":"persistency_manager  <code>instance-attribute</code>","text":"<pre><code>persistency_manager: PersistencyManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper.runtime_manager","title":"runtime_manager  <code>instance-attribute</code>","text":"<pre><code>runtime_manager: RuntimeManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper.output_parser","title":"output_parser  <code>instance-attribute</code>","text":"<pre><code>output_parser: BaseModelOutputParser\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper.conditioning_parser","title":"conditioning_parser  <code>instance-attribute</code>","text":"<pre><code>conditioning_parser: BaseConditioningParser\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper.max_unique_instances","title":"max_unique_instances  <code>instance-attribute</code>","text":"<pre><code>max_unique_instances: int\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper.hashing_function","title":"hashing_function  <code>instance-attribute</code>","text":"<pre><code>hashing_function: Callable[[Any], str]\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper.func","title":"func  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>func: Callable = field(init=False)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper.wrap","title":"wrap","text":"<pre><code>wrap(func: Callable) -&gt; Callable\n</code></pre> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>def wrap(self, func: Callable) -&gt; Callable:\n    self.func = deepcopy(func)\n\n    @wraps(func)\n    def wrapped(obj_self, *args, **kwargs) -&gt; Any:\n        model_hash = self.hashing_function(obj_self)\n        model_cls_name = obj_self.__class__.__name__\n        conditioning = self.conditioning_parser.parse_conditioning(func, *args, **kwargs)\n        kwargs.pop(CONDITIONING_METADATA_FIELDNAME, None)\n\n        conditioning = self._resolve_conditioning(conditioning)\n        generator, existing_generations = self._get_generations(model_hash, conditioning, model_cls_name)\n\n        max_unique_instances = generator.model_metadata.get(\"max_unique_instances\", 1)\n        next_instance = (conditioning.value_metadata.get(\"latest_instance\", -1) + 1) % max_unique_instances\n\n        if not self.persistency_manager.enabled:\n            logger.info(\"PersistencyManager is disabled. Output will be generated.\")\n            model_output = func(obj_self, *args, **kwargs)\n\n            if not existing_generations:\n                sample = self._create_sample_placeholder(conditioning=conditioning, generator=generator)\n                self._finish_sample_generation(\n                    sample=sample,\n                    model_output=model_output,\n                    conditioning=conditioning,\n                    generator=generator,\n                )\n\n            return model_output\n\n        if len(existing_generations) &gt;= max_unique_instances:\n            logger.info(f\"Max instances ({max_unique_instances}) reached. Returning existing generation\")\n\n            model_output = self._return_existing_generation(\n                existing_generations=existing_generations,\n                generator=generator,\n                generation_id=next_instance,\n            )\n\n            self.update_generation_id(conditioning, next_instance)\n\n            return model_output\n\n        sample_placeholder = self._create_sample_placeholder(\n            conditioning=conditioning, generator=generator, generation_id=next_instance\n        )\n\n        try:\n            model_output = func(obj_self, *args, **kwargs)\n\n        except Exception as e:\n            self.db_manager.update(\n                model=SampleTable,\n                filters={\"id\": sample_placeholder.id},\n                values={\"status\": SampleStatus.FAILED.value},\n            )\n            logger.error(f\"Could not generate sample: {e}\")\n            raise e\n\n        self._finish_sample_generation(\n            sample=sample_placeholder,\n            model_output=model_output,\n            conditioning=conditioning,\n            generator=generator,\n            generation_id=next_instance,\n        )\n        self.update_generation_id(conditioning, next_instance)\n        return model_output\n\n    return wrapped\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper.attach_artifacts_to_sample","title":"attach_artifacts_to_sample","text":"<pre><code>attach_artifacts_to_sample(sample: Sample) -&gt; None\n</code></pre> <p>Attach artifacts to a sample.</p> PARAMETER DESCRIPTION <code>sample</code> <p>The sample to attach artifacts to.</p> <p> TYPE: <code>Sample</code> </p> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>def attach_artifacts_to_sample(self, sample: Sample) -&gt; None:\n    \"\"\"Attach artifacts to a sample.\n\n    Args:\n        sample: The sample to attach artifacts to.\n    \"\"\"\n    while self.runtime_manager.artifacts_for_next_sample:\n        artifact = self.runtime_manager.artifacts_for_next_sample.popleft()\n\n        existing_artifacts = self.db_manager.search(\n            ArtifactTable, {\"name\": artifact.name, \"hash\": artifact.hash, \"sample_id\": sample.id}\n        )\n\n        if existing_artifacts:\n            logger.info(f\"Artifact {artifact.name} already exists in the database.\")\n\n        else:  # noqa: PLR5501\n            if self.persistency_manager.enabled:\n                value = artifact.value\n                artifact.value = None\n                artifact.sample_id = sample.id\n                artifact.hash = get_hash_from_jsonable(value)\n                artifact = Artifact.from_orm(self.db_manager.save(artifact.to_orm()))\n                artifact.value = value\n                self.persistency_manager.save_artifact(artifact)\n                logger.info(f\"Saved artifact #{artifact.id} (sample #{sample.id}) to database and disk.\")\n            else:\n                artifact = Artifact.from_orm(self.db_manager.save(artifact.to_orm()))\n                logger.info(f\"Saved artifact #{artifact.id} (sample #{sample.id}) to database.\")\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.MethodWrapper.update_generation_id","title":"update_generation_id","text":"<pre><code>update_generation_id(\n    conditioning: Conditioning, generation_id: int\n)\n</code></pre> <p>Update the generation_id of the most recently used generation.</p> PARAMETER DESCRIPTION <code>conditioning</code> <p>The conditioning.</p> <p> TYPE: <code>Conditioning</code> </p> <code>generation_id</code> <p>The generation id.</p> <p> TYPE: <code>int</code> </p> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>def update_generation_id(self, conditioning: Conditioning, generation_id: int):\n    \"\"\"Update the generation_id of the most recently used generation.\n\n    Args:\n        conditioning: The conditioning.\n        generation_id: The generation id.\n    \"\"\"\n    conditioning_metadata = conditioning.value_metadata\n    conditioning_metadata[\"latest_instance\"] = generation_id\n\n    self.db_manager.update(\n        model=ConditioningTable, filters={\"id\": conditioning.id}, values={\"value_metadata\": conditioning_metadata}\n    )\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper","title":"genai_monitor.injectors.wrapper.FunctionWrapper","text":"<p>               Bases: <code>Wrapper</code></p> <p>Wrapper for functions.</p>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper.db_manager","title":"db_manager  <code>instance-attribute</code>","text":"<pre><code>db_manager: DBManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper.persistency_manager","title":"persistency_manager  <code>instance-attribute</code>","text":"<pre><code>persistency_manager: PersistencyManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper.runtime_manager","title":"runtime_manager  <code>instance-attribute</code>","text":"<pre><code>runtime_manager: RuntimeManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper.output_parser","title":"output_parser  <code>instance-attribute</code>","text":"<pre><code>output_parser: BaseModelOutputParser\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper.conditioning_parser","title":"conditioning_parser  <code>instance-attribute</code>","text":"<pre><code>conditioning_parser: BaseConditioningParser\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper.max_unique_instances","title":"max_unique_instances  <code>instance-attribute</code>","text":"<pre><code>max_unique_instances: int\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper.hashing_function","title":"hashing_function  <code>instance-attribute</code>","text":"<pre><code>hashing_function: Callable[[Any], str]\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper.func","title":"func  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>func: Callable = field(init=False)\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper.wrap","title":"wrap","text":"<pre><code>wrap(func: Callable) -&gt; Callable\n</code></pre> <p>Wraps the function.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function to wrap.</p> <p> TYPE: <code>Callable</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>The wrapped function.</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>def wrap(self, func: Callable) -&gt; Callable:\n    \"\"\"Wraps the function.\n\n    Args:\n        func: The function to wrap.\n\n    Returns:\n        Callable: The wrapped function.\n    \"\"\"\n    self.func = deepcopy(func)\n\n    @wraps(func)\n    def wrapped(*args, **kwargs) -&gt; Any:\n        function_hash = self.hashing_function(func)\n        function_name = func.__name__\n\n        conditioning = self.conditioning_parser.parse_conditioning(func, *args, **kwargs)\n        kwargs.pop(CONDITIONING_METADATA_FIELDNAME, None)\n\n        conditioning = self._resolve_conditioning(conditioning)\n        generator, existing_generations = self._get_generations(function_hash, conditioning, function_name)\n\n        max_unique_instances = generator.model_metadata.get(\"max_unique_instances\", 1)\n        next_instance = (conditioning.value_metadata.get(\"latest_instance\", -1) + 1) % max_unique_instances\n\n        if not self.persistency_manager.enabled:\n            logger.info(\"PersistencyManager is disabled. Output will be generated.\")\n            model_output = func(*args, **kwargs)\n\n            if not existing_generations:\n                sample = self._create_sample_placeholder(conditioning=conditioning, generator=generator)\n                self._finish_sample_generation(\n                    sample=sample,\n                    model_output=model_output,\n                    conditioning=conditioning,\n                    generator=generator,\n                )\n\n            return model_output\n\n        if len(existing_generations) &gt;= max_unique_instances:\n            logger.info(f\"Max instances ({max_unique_instances}) reached. Returning existing generation.\")\n            try:\n                model_output = self._return_existing_generation(\n                    existing_generations=existing_generations,\n                    generator=generator,\n                    generation_id=next_instance,\n                )\n\n                self.update_generation_id(conditioning, next_instance)\n\n                return model_output\n\n            except Exception as e:\n                logger.error(f\"Could not return existing generation: {e}\")\n                logger.info(\"Generating new sample without sample creation.\")\n                return func(*args, **kwargs)\n\n        sample_placeholder = self._create_sample_placeholder(\n            conditioning=conditioning, generator=generator, generation_id=next_instance\n        )\n\n        try:\n            model_output = func(*args, **kwargs)\n\n        except Exception as e:\n            self.db_manager.update(\n                model=SampleTable,\n                filters={\"id\": sample_placeholder.id},\n                values={\"status\": SampleStatus.FAILED.value},\n            )\n            logger.error(f\"Could not generate sample: {e}\")\n            raise e\n\n        self._finish_sample_generation(\n            sample=sample_placeholder,\n            model_output=model_output,\n            conditioning=conditioning,\n            generator=generator,\n            generation_id=next_instance,\n        )\n        self.update_generation_id(conditioning, next_instance)\n        return model_output\n\n    return wrapped\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper.attach_artifacts_to_sample","title":"attach_artifacts_to_sample","text":"<pre><code>attach_artifacts_to_sample(sample: Sample) -&gt; None\n</code></pre> <p>Attach artifacts to a sample.</p> PARAMETER DESCRIPTION <code>sample</code> <p>The sample to attach artifacts to.</p> <p> TYPE: <code>Sample</code> </p> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>def attach_artifacts_to_sample(self, sample: Sample) -&gt; None:\n    \"\"\"Attach artifacts to a sample.\n\n    Args:\n        sample: The sample to attach artifacts to.\n    \"\"\"\n    while self.runtime_manager.artifacts_for_next_sample:\n        artifact = self.runtime_manager.artifacts_for_next_sample.popleft()\n\n        existing_artifacts = self.db_manager.search(\n            ArtifactTable, {\"name\": artifact.name, \"hash\": artifact.hash, \"sample_id\": sample.id}\n        )\n\n        if existing_artifacts:\n            logger.info(f\"Artifact {artifact.name} already exists in the database.\")\n\n        else:  # noqa: PLR5501\n            if self.persistency_manager.enabled:\n                value = artifact.value\n                artifact.value = None\n                artifact.sample_id = sample.id\n                artifact.hash = get_hash_from_jsonable(value)\n                artifact = Artifact.from_orm(self.db_manager.save(artifact.to_orm()))\n                artifact.value = value\n                self.persistency_manager.save_artifact(artifact)\n                logger.info(f\"Saved artifact #{artifact.id} (sample #{sample.id}) to database and disk.\")\n            else:\n                artifact = Artifact.from_orm(self.db_manager.save(artifact.to_orm()))\n                logger.info(f\"Saved artifact #{artifact.id} (sample #{sample.id}) to database.\")\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.FunctionWrapper.update_generation_id","title":"update_generation_id","text":"<pre><code>update_generation_id(\n    conditioning: Conditioning, generation_id: int\n)\n</code></pre> <p>Update the generation_id of the most recently used generation.</p> PARAMETER DESCRIPTION <code>conditioning</code> <p>The conditioning.</p> <p> TYPE: <code>Conditioning</code> </p> <code>generation_id</code> <p>The generation id.</p> <p> TYPE: <code>int</code> </p> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>def update_generation_id(self, conditioning: Conditioning, generation_id: int):\n    \"\"\"Update the generation_id of the most recently used generation.\n\n    Args:\n        conditioning: The conditioning.\n        generation_id: The generation id.\n    \"\"\"\n    conditioning_metadata = conditioning.value_metadata\n    conditioning_metadata[\"latest_instance\"] = generation_id\n\n    self.db_manager.update(\n        model=ConditioningTable, filters={\"id\": conditioning.id}, values={\"value_metadata\": conditioning_metadata}\n    )\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.WrapperFactory","title":"genai_monitor.injectors.wrapper.WrapperFactory","text":"<p>Factory for creating wrappers for functions and methods.</p>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.WrapperFactory.create","title":"create  <code>staticmethod</code>","text":"<pre><code>create(\n    func: Callable,\n    db_manager: DBManager,\n    persistency_manager: PersistencyManager,\n    runtime_manager: RuntimeManager,\n    output_parser: BaseModelOutputParser,\n    conditioning_parser: BaseConditioningParser,\n    hashing_function: Callable[[Any], str],\n    max_unique_instances: int = 1,\n) -&gt; Union[FunctionWrapper, MethodWrapper]\n</code></pre> <p>Creates a wrapper for a function or method.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function or method to wrap.</p> <p> TYPE: <code>Callable</code> </p> <code>db_manager</code> <p>The database manager.</p> <p> TYPE: <code>DBManager</code> </p> <code>persistency_manager</code> <p>The persistency manager.</p> <p> TYPE: <code>PersistencyManager</code> </p> <code>runtime_manager</code> <p>The runtime manager.</p> <p> TYPE: <code>RuntimeManager</code> </p> <code>output_parser</code> <p>The output parser.</p> <p> TYPE: <code>BaseModelOutputParser</code> </p> <code>conditioning_parser</code> <p>The conditioning parser.</p> <p> TYPE: <code>BaseConditioningParser</code> </p> <code>hashing_function</code> <p>The hashing function.</p> <p> TYPE: <code>Callable[[Any], str]</code> </p> <code>max_unique_instances</code> <p>The maximum number of unique sample instances for each conditioning.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>Union[FunctionWrapper, MethodWrapper]</code> <p>The wrapper for the function or method.</p> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>@staticmethod\ndef create(\n    func: Callable,\n    db_manager: DBManager,\n    persistency_manager: PersistencyManager,\n    runtime_manager: RuntimeManager,\n    output_parser: BaseModelOutputParser,\n    conditioning_parser: BaseConditioningParser,\n    hashing_function: Callable[[Any], str],\n    max_unique_instances: int = 1,\n) -&gt; Union[FunctionWrapper, MethodWrapper]:\n    \"\"\"Creates a wrapper for a function or method.\n\n    Args:\n        func: The function or method to wrap.\n        db_manager: The database manager.\n        persistency_manager: The persistency manager.\n        runtime_manager: The runtime manager.\n        output_parser: The output parser.\n        conditioning_parser: The conditioning parser.\n        hashing_function: The hashing function.\n        max_unique_instances: The maximum number of unique sample instances for each conditioning.\n\n    Returns:\n        The wrapper for the function or method.\n    \"\"\"\n    if is_class_func(func=func):\n        return MethodWrapper(\n            db_manager=db_manager,\n            persistency_manager=persistency_manager,\n            runtime_manager=runtime_manager,\n            output_parser=output_parser,\n            conditioning_parser=conditioning_parser,\n            hashing_function=hashing_function,\n            max_unique_instances=max_unique_instances,\n        )\n\n    return FunctionWrapper(\n        db_manager=db_manager,\n        persistency_manager=persistency_manager,\n        runtime_manager=runtime_manager,\n        output_parser=output_parser,\n        conditioning_parser=conditioning_parser,\n        hashing_function=hashing_function,\n        max_unique_instances=max_unique_instances,\n    )\n</code></pre>"},{"location":"api_reference/injectors/#artifacts","title":"Artifacts","text":""},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactMethodWrapper","title":"genai_monitor.injectors.wrapper.ArtifactMethodWrapper","text":"<p>               Bases: <code>ArtifactWrapper</code></p> <p>Wrapper for methods for artifact tracking.</p>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactMethodWrapper.db_manager","title":"db_manager  <code>instance-attribute</code>","text":"<pre><code>db_manager: DBManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactMethodWrapper.persistency_manager","title":"persistency_manager  <code>instance-attribute</code>","text":"<pre><code>persistency_manager: PersistencyManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactMethodWrapper.runtime_manager","title":"runtime_manager  <code>instance-attribute</code>","text":"<pre><code>runtime_manager: RuntimeManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactMethodWrapper.wrap_forward","title":"wrap_forward","text":"<pre><code>wrap_forward(func: Callable) -&gt; Callable\n</code></pre> <p>Wraps the function for forward artifact tracking.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function to wrap.</p> <p> TYPE: <code>Callable</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>The wrapped function.</p> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>def wrap_forward(self, func: Callable) -&gt; Callable:\n    \"\"\"Wraps the function for forward artifact tracking.\n\n    Args:\n        func: The function to wrap.\n\n    Returns:\n        The wrapped function.\n    \"\"\"\n    self.func = deepcopy(func)\n\n    @wraps(func)\n    def wrapped(obj_self, *args, **kwargs) -&gt; Any:\n        output = func(*args, **kwargs)\n        self._add_artifact_to_queue(output=output, name=f\"{obj_self.__class__.__name__}.{func.__name__}\")\n        return output\n\n    return wrapped\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactMethodWrapper.wrap_backward","title":"wrap_backward","text":"<pre><code>wrap_backward(func: Callable) -&gt; Callable\n</code></pre> <p>Wraps the function for backward artifact tracking.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function to wrap.</p> <p> TYPE: <code>Callable</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>The wrapped function.</p> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>def wrap_backward(self, func: Callable) -&gt; Callable:\n    \"\"\"Wraps the function for backward artifact tracking.\n\n    Args:\n        func: The function to wrap.\n\n    Returns:\n        The wrapped function.\n    \"\"\"\n    self.func = deepcopy(func)\n\n    @wraps(func)\n    def wrapped(obj_self, *args, **kwargs) -&gt; Any:\n        output = func(*args, **kwargs)\n        self._save_artifact(output, name=f\"{obj_self.__class__.__name__}.{func.__name__}\")\n        return output\n\n    return wrapped\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactFunctionWrapper","title":"genai_monitor.injectors.wrapper.ArtifactFunctionWrapper","text":"<p>               Bases: <code>ArtifactWrapper</code></p> <p>Wrapper for functions for artifact tracking.</p>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactFunctionWrapper.db_manager","title":"db_manager  <code>instance-attribute</code>","text":"<pre><code>db_manager: DBManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactFunctionWrapper.persistency_manager","title":"persistency_manager  <code>instance-attribute</code>","text":"<pre><code>persistency_manager: PersistencyManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactFunctionWrapper.runtime_manager","title":"runtime_manager  <code>instance-attribute</code>","text":"<pre><code>runtime_manager: RuntimeManager\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactFunctionWrapper.wrap_forward","title":"wrap_forward","text":"<pre><code>wrap_forward(func: Callable) -&gt; Callable\n</code></pre> <p>Wraps the function for forward artifact tracking.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function to wrap.</p> <p> TYPE: <code>Callable</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>The wrapped function.</p> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>def wrap_forward(self, func: Callable) -&gt; Callable:\n    \"\"\"Wraps the function for forward artifact tracking.\n\n    Args:\n        func: The function to wrap.\n\n    Returns:\n        The wrapped function.\n    \"\"\"\n    self.func = deepcopy(func)\n\n    @wraps(func)\n    def wrapped(*args, **kwargs) -&gt; Any:\n        output = func(*args, **kwargs)\n        self._add_artifact_to_queue(output=output, name=f\"{func.__module__}.{func.__name__}\")\n        return output\n\n    return wrapped\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactFunctionWrapper.wrap_backward","title":"wrap_backward","text":"<pre><code>wrap_backward(func: Callable) -&gt; Callable\n</code></pre> <p>Wraps the function for backward artifact tracking.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function to wrap.</p> <p> TYPE: <code>Callable</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>The wrapped function.</p> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>def wrap_backward(self, func: Callable) -&gt; Callable:\n    \"\"\"Wraps the function for backward artifact tracking.\n\n    Args:\n        func: The function to wrap.\n\n    Returns:\n        The wrapped function.\n    \"\"\"\n    self.func = deepcopy(func)\n\n    @wraps(func)\n    def wrapped(*args, **kwargs) -&gt; Any:\n        output = func(*args, **kwargs)\n        self._save_artifact(output, name=f\"{func.__module__}.{func.__name__}\")\n        return output\n\n    return wrapped\n</code></pre>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactWrapperFactory","title":"genai_monitor.injectors.wrapper.ArtifactWrapperFactory","text":"<p>Factory for creating wrappers for artifacts.</p>"},{"location":"api_reference/injectors/#genai_monitor.injectors.wrapper.ArtifactWrapperFactory.create","title":"create","text":"<pre><code>create(\n    func: Callable,\n    db_manager: DBManager,\n    persistency_manager: PersistencyManager,\n    runtime_manager: RuntimeManager,\n) -&gt; Union[ArtifactFunctionWrapper, ArtifactMethodWrapper]\n</code></pre> <p>Creates a wrapper for an artifact.</p> PARAMETER DESCRIPTION <code>func</code> <p>The artifact to wrap.</p> <p> TYPE: <code>Callable</code> </p> <code>db_manager</code> <p>The database manager.</p> <p> TYPE: <code>DBManager</code> </p> <code>persistency_manager</code> <p>The persistency manager.</p> <p> TYPE: <code>PersistencyManager</code> </p> <code>runtime_manager</code> <p>The runtime manager.</p> <p> TYPE: <code>RuntimeManager</code> </p> RETURNS DESCRIPTION <code>Union[ArtifactFunctionWrapper, ArtifactMethodWrapper]</code> <p>The wrapper for the artifact.</p> Source code in <code>src/genai_monitor/injectors/wrapper.py</code> <pre><code>def create(\n    self,\n    func: Callable,\n    db_manager: DBManager,\n    persistency_manager: PersistencyManager,\n    runtime_manager: RuntimeManager,\n) -&gt; Union[ArtifactFunctionWrapper, ArtifactMethodWrapper]:\n    \"\"\"Creates a wrapper for an artifact.\n\n    Args:\n        func: The artifact to wrap.\n        db_manager: The database manager.\n        persistency_manager: The persistency manager.\n        runtime_manager: The runtime manager.\n\n    Returns:\n        The wrapper for the artifact.\n    \"\"\"\n    if is_class_func(func=func):\n        return ArtifactMethodWrapper(\n            db_manager=db_manager, persistency_manager=persistency_manager, runtime_manager=runtime_manager\n        )\n\n    return ArtifactFunctionWrapper(\n        db_manager=db_manager, persistency_manager=persistency_manager, runtime_manager=runtime_manager\n    )\n</code></pre>"},{"location":"api_reference/query/","title":"Query","text":""},{"location":"api_reference/query/#core-query-api-implementation","title":"Core query API implementation","text":""},{"location":"api_reference/query/#genai_monitor.query.api.get_conditionings","title":"genai_monitor.query.api.get_conditionings","text":"<pre><code>get_conditionings() -&gt; List[Conditioning]\n</code></pre> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def get_conditionings() -&gt; List[Conditioning]:\n    results = DBManager.search(ConditioningTable)\n    return [Conditioning.from_orm(result) for result in results]\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.get_models","title":"genai_monitor.query.api.get_models","text":"<pre><code>get_models() -&gt; List[Model]\n</code></pre> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def get_models() -&gt; List[Model]:\n    results = DBManager.search(ModelTable)\n    return [Model.from_orm(result) for result in results]\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.get_samples","title":"genai_monitor.query.api.get_samples","text":"<pre><code>get_samples() -&gt; List[Sample]\n</code></pre> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def get_samples() -&gt; List[Sample]:\n    results = DBManager.search(SampleTable)\n    return [Sample.from_orm(result) for result in results]\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.get_sample_by_hash","title":"genai_monitor.query.api.get_sample_by_hash","text":"<pre><code>get_sample_by_hash(hash_value: str) -&gt; Optional[Sample]\n</code></pre> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def get_sample_by_hash(hash_value: str) -&gt; Optional[Sample]:\n    results = DBManager.search(SampleTable, filters={\"hash\": hash_value})\n    return Sample.from_orm(results[0]) if results else None\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.get_sample_by_id","title":"genai_monitor.query.api.get_sample_by_id","text":"<pre><code>get_sample_by_id(sample_id: int) -&gt; Optional[Sample]\n</code></pre> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def get_sample_by_id(sample_id: int) -&gt; Optional[Sample]:\n    results = DBManager.search(SampleTable, filters={\"id\": sample_id})\n    return Sample.from_orm(results[0]) if results else None\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.get_conditioning_by_id","title":"genai_monitor.query.api.get_conditioning_by_id","text":"<pre><code>get_conditioning_by_id(\n    conditioning_id: int,\n) -&gt; Optional[Conditioning]\n</code></pre> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def get_conditioning_by_id(conditioning_id: int) -&gt; Optional[Conditioning]:\n    results = DBManager.search(ConditioningTable, filters={\"id\": conditioning_id})\n    return Conditioning.from_orm(results[0]) if results else None\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.get_model_by_id","title":"genai_monitor.query.api.get_model_by_id","text":"<pre><code>get_model_by_id(model_id: int) -&gt; Optional[Model]\n</code></pre> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def get_model_by_id(model_id: int) -&gt; Optional[Model]:\n    results = DBManager.search(ModelTable, filters={\"id\": model_id})\n    return Model.from_orm(results[0]) if results else None\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.SampleQuery","title":"genai_monitor.query.api.SampleQuery","text":"<pre><code>SampleQuery(sample: Sample)\n</code></pre> <p>Query interface for samples.</p> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def __init__(self, sample: Sample):\n    self._sample = sample\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.SampleQuery.get_conditioning","title":"get_conditioning","text":"<pre><code>get_conditioning() -&gt; Optional[Conditioning]\n</code></pre> <p>Get the conditioning used to generate this sample.</p> RETURNS DESCRIPTION <code>Optional[Conditioning]</code> <p>Optional[Conditioning]: The conditioning if it exists, None otherwise.</p> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def get_conditioning(self) -&gt; Optional[Conditioning]:\n    \"\"\"Get the conditioning used to generate this sample.\n\n    Returns:\n        Optional[Conditioning]: The conditioning if it exists, None otherwise.\n    \"\"\"\n    if not self._sample.conditioning_id:\n        return None\n\n    results = DBManager.search(ConditioningTable, filters={\"id\": self._sample.conditioning_id})\n    return Conditioning.from_orm(results[0]) if results else None\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.SampleQuery.get_model","title":"get_model","text":"<pre><code>get_model() -&gt; Optional[Model]\n</code></pre> <p>Get the generator that created this sample.</p> RETURNS DESCRIPTION <code>Optional[Model]</code> <p>Optional[Model]: The generator if it exists, None otherwise.</p> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def get_model(self) -&gt; Optional[Model]:\n    \"\"\"Get the generator that created this sample.\n\n    Returns:\n        Optional[Model]: The generator if it exists, None otherwise.\n    \"\"\"\n    if not self._sample.model_id:\n        return None\n\n    results = DBManager.search(ModelTable, filters={\"id\": self._sample.model_id})\n    return Model.from_orm(results[0]) if results else None\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.ModelQuery","title":"genai_monitor.query.api.ModelQuery","text":"<pre><code>ModelQuery(model: Model)\n</code></pre> <p>Query interface for generators.</p> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def __init__(self, model: Model):\n    self._model = model\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.ModelQuery.get_samples","title":"get_samples","text":"<pre><code>get_samples(\n    conditioning: Optional[Conditioning] = None,\n) -&gt; List[Sample]\n</code></pre> <p>Get all samples generated by this generator.</p> PARAMETER DESCRIPTION <code>conditioning</code> <p>Optional conditioning to filter samples</p> <p> TYPE: <code>Optional[Conditioning]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>List[Sample]</code> <p>List of samples</p> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def get_samples(self, conditioning: Optional[Conditioning] = None) -&gt; List[Sample]:\n    \"\"\"Get all samples generated by this generator.\n\n    Args:\n        conditioning: Optional conditioning to filter samples\n\n    Returns:\n        List of samples\n    \"\"\"\n    filters = {\"model_id\": self._model.id}\n    if conditioning:\n        filters[\"conditioning_id\"] = conditioning.id\n\n    results = DBManager.search(SampleTable, filters=filters)\n    return [Sample.from_orm(result) for result in results]\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.ConditioningQuery","title":"genai_monitor.query.api.ConditioningQuery","text":"<pre><code>ConditioningQuery(conditioning: Conditioning)\n</code></pre> <p>Query interface for conditionings.</p> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def __init__(self, conditioning: Conditioning):\n    self._conditioning = conditioning\n</code></pre>"},{"location":"api_reference/query/#genai_monitor.query.api.ConditioningQuery.get_samples","title":"get_samples","text":"<pre><code>get_samples() -&gt; List[Sample]\n</code></pre> <p>Get all samples generated with this conditioning.</p> RETURNS DESCRIPTION <code>List[Sample]</code> <p>List[Sample]: List of samples generated with this conditioning.</p> Source code in <code>src/genai_monitor/query/api.py</code> <pre><code>def get_samples(self) -&gt; List[Sample]:\n    \"\"\"Get all samples generated with this conditioning.\n\n    Returns:\n        List[Sample]: List of samples generated with this conditioning.\n    \"\"\"\n    results = DBManager.search(SampleTable, filters={\"conditioning_id\": self._conditioning.id})\n    return [Sample.from_orm(result) for result in results]\n</code></pre>"},{"location":"api_reference/registration/","title":"Custom registration","text":""},{"location":"api_reference/registration/#genai_monitor.registration.api.register_function","title":"genai_monitor.registration.api.register_function","text":"<pre><code>register_function(\n    func: Callable,\n    model_output_to_bytes: Callable[[Any], bytes],\n    bytes_to_model_output: Callable[[bytes], Any],\n    model_output_to_base_type: Optional[\n        Callable[[Any], BaseType]\n    ] = None,\n    parse_inference_method_arguments: Optional[\n        Callable[[Dict[str, Any]], Jsonable]\n    ] = None,\n    model_hashing_function: Optional[\n        Callable[[object], str]\n    ] = None,\n    max_unique_instances: int = 1,\n)\n</code></pre> <p>Registers a function.</p> PARAMETER DESCRIPTION <code>func</code> <p>The function to register.</p> <p> TYPE: <code>Callable</code> </p> <code>model_output_to_bytes</code> <p>The function to convert the model output to bytes.</p> <p> TYPE: <code>Callable[[Any], bytes]</code> </p> <code>bytes_to_model_output</code> <p>The function to convert bytes to the model output.</p> <p> TYPE: <code>Callable[[bytes], Any]</code> </p> <code>model_output_to_base_type</code> <p>The function to convert the model output to a base type.</p> <p> TYPE: <code>Optional[Callable[[Any], BaseType]]</code> DEFAULT: <code>None</code> </p> <code>parse_inference_method_arguments</code> <p>The function to parse the inference method arguments.</p> <p> TYPE: <code>Optional[Callable[[Dict[str, Any]], Jsonable]]</code> DEFAULT: <code>None</code> </p> <code>model_hashing_function</code> <p>The function to hash the model.</p> <p> TYPE: <code>Optional[Callable[[object], str]]</code> DEFAULT: <code>None</code> </p> <code>max_unique_instances</code> <p>The maximum number of unique sample instances for each conditioning.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> Source code in <code>src/genai_monitor/registration/api.py</code> <pre><code>def register_function(\n    func: Callable,\n    model_output_to_bytes: Callable[[Any], bytes],\n    bytes_to_model_output: Callable[[bytes], Any],\n    model_output_to_base_type: Optional[Callable[[Any], BaseType]] = None,\n    parse_inference_method_arguments: Optional[Callable[[Dict[str, Any]], Jsonable]] = None,\n    model_hashing_function: Optional[Callable[[object], str]] = None,\n    max_unique_instances: int = 1,\n):\n    \"\"\"Registers a function.\n\n    Args:\n        func: The function to register.\n        model_output_to_bytes: The function to convert the model output to bytes.\n        bytes_to_model_output: The function to convert bytes to the model output.\n        model_output_to_base_type: The function to convert the model output to a base type.\n        parse_inference_method_arguments: The function to parse the inference method arguments.\n        model_hashing_function: The function to hash the model.\n        max_unique_instances: The maximum number of unique sample instances for each conditioning.\n    \"\"\"\n    func_name = f\"{func.__module__}.{func.__name__}\"\n\n    if parse_inference_method_arguments is None:\n        conditioning_parser = DefaultConditioningParser()\n    else:\n        conditioning_parser = _make_cls(\n            cls_name=_make_conditioning_parser_name(func_name),\n            base=BaseConditioningParser,\n            method_mapper={\"parse_func_arguments\": parse_inference_method_arguments},\n        )()\n\n    conditioning_parser.max_unique_instances = max_unique_instances  # type: ignore\n\n    output_parser_method_mapper = {\n        \"model_output_to_bytes\": model_output_to_bytes,\n        \"bytes_to_model_output\": bytes_to_model_output,\n    }\n\n    if model_output_to_base_type is not None:\n        output_parser_method_mapper[\"model_output_to_base_type\"] = model_output_to_base_type\n\n    output_parser = _make_cls(\n        cls_name=_make_output_parser_name(func.__name__),\n        base=BaseModelOutputParser,\n        method_mapper=output_parser_method_mapper,\n    )()\n\n    if not model_hashing_function:\n        model_hashing_function = default_model_hashing_function\n\n    register_inference_method(\n        inference_method=func,\n        output_parser=output_parser,\n        conditioning_parser=conditioning_parser,\n        hashing_function=model_hashing_function,\n        max_unique_instances=max_unique_instances,\n    )\n</code></pre>"},{"location":"api_reference/registration/#genai_monitor.registration.api.register_class","title":"genai_monitor.registration.api.register_class","text":"<pre><code>register_class(\n    cls: Type,\n    inference_methods: List[str],\n    model_output_to_bytes: Callable[[Any], bytes],\n    bytes_to_model_output: Callable[[bytes], Any],\n    model_output_to_base_type: Optional[\n        Callable[[Any], BaseType]\n    ] = None,\n    parse_inference_method_arguments: Optional[\n        Callable[[Dict[str, Any]], Jsonable]\n    ] = None,\n    model_hashing_function: Optional[\n        Callable[[object], str]\n    ] = None,\n    max_unique_instances: int = 1,\n)\n</code></pre> <p>Registers a class with inference methods.</p> PARAMETER DESCRIPTION <code>cls</code> <p>The class to register.</p> <p> TYPE: <code>Type</code> </p> <code>inference_methods</code> <p>The names of the inference methods.</p> <p> TYPE: <code>List[str]</code> </p> <code>model_output_to_bytes</code> <p>The function to convert the model output to bytes.</p> <p> TYPE: <code>Callable[[Any], bytes]</code> </p> <code>bytes_to_model_output</code> <p>The function to convert bytes to the model output.</p> <p> TYPE: <code>Callable[[bytes], Any]</code> </p> <code>model_output_to_base_type</code> <p>The function to convert the model output to a base type.</p> <p> TYPE: <code>Optional[Callable[[Any], BaseType]]</code> DEFAULT: <code>None</code> </p> <code>parse_inference_method_arguments</code> <p>The function to parse the inference method arguments.</p> <p> TYPE: <code>Optional[Callable[[Dict[str, Any]], Jsonable]]</code> DEFAULT: <code>None</code> </p> <code>model_hashing_function</code> <p>The function to hash the model.</p> <p> TYPE: <code>Optional[Callable[[object], str]]</code> DEFAULT: <code>None</code> </p> <code>max_unique_instances</code> <p>The maximum number of unique sample instances for each conditioning.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> Source code in <code>src/genai_monitor/registration/api.py</code> <pre><code>def register_class(\n    cls: Type,\n    inference_methods: List[str],\n    model_output_to_bytes: Callable[[Any], bytes],\n    bytes_to_model_output: Callable[[bytes], Any],\n    model_output_to_base_type: Optional[Callable[[Any], BaseType]] = None,\n    parse_inference_method_arguments: Optional[Callable[[Dict[str, Any]], Jsonable]] = None,\n    model_hashing_function: Optional[Callable[[object], str]] = None,\n    max_unique_instances: int = 1,\n):\n    \"\"\"Registers a class with inference methods.\n\n    Args:\n        cls: The class to register.\n        inference_methods: The names of the inference methods.\n        model_output_to_bytes: The function to convert the model output to bytes.\n        bytes_to_model_output: The function to convert bytes to the model output.\n        model_output_to_base_type: The function to convert the model output to a base type.\n        parse_inference_method_arguments: The function to parse the inference method arguments.\n        model_hashing_function: The function to hash the model.\n        max_unique_instances: The maximum number of unique sample instances for each conditioning.\n    \"\"\"\n    cls_name = cls.__name__\n    methods_to_wrap = [getattr(cls, method_name) for method_name in inference_methods]\n    if parse_inference_method_arguments is None:\n        conditioning_parser = DefaultConditioningParser()\n    else:\n        conditioning_parser = _make_cls(\n            cls_name=_make_conditioning_parser_name(cls_name),\n            base=BaseConditioningParser,\n            method_mapper={\"parse_func_arguments\": parse_inference_method_arguments},\n        )()\n\n    output_parser_method_mapper = {\n        \"model_output_to_bytes\": model_output_to_bytes,\n        \"bytes_to_model_output\": bytes_to_model_output,\n    }\n\n    if model_output_to_base_type is not None:\n        output_parser_method_mapper[\"model_output_to_base_type\"] = model_output_to_base_type\n\n    output_parser = _make_cls(\n        cls_name=_make_output_parser_name(cls_name),\n        base=BaseModelOutputParser,\n        method_mapper=output_parser_method_mapper,\n    )()\n\n    if not model_hashing_function:\n        model_hashing_function = default_model_hashing_function\n\n    for inference_method in methods_to_wrap:\n        register_inference_method(\n            inference_method=inference_method,\n            output_parser=output_parser,\n            conditioning_parser=conditioning_parser,\n            hashing_function=model_hashing_function,\n            max_unique_instances=max_unique_instances,\n        )\n</code></pre>"},{"location":"api_reference/structures/","title":"Core structures","text":""},{"location":"api_reference/structures/#conditioning-parser","title":"Conditioning Parser","text":""},{"location":"api_reference/structures/#genai_monitor.structures.conditioning_parsers.base.BaseConditioningParser","title":"genai_monitor.structures.conditioning_parsers.base.BaseConditioningParser","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for conditioning parsers.</p> <p>Use it to create custom conditioning parsers, not available natively in the library.</p> <p>'parse_func_arguments' is the core method that needs to be overwritten by the subclasses.</p>"},{"location":"api_reference/structures/#genai_monitor.structures.conditioning_parsers.base.BaseConditioningParser.db_manager","title":"db_manager  <code>instance-attribute</code>","text":"<pre><code>db_manager: DBManager\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.conditioning_parsers.base.BaseConditioningParser.persistency_manager","title":"persistency_manager  <code>instance-attribute</code>","text":"<pre><code>persistency_manager: PersistencyManager\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.conditioning_parsers.base.BaseConditioningParser.parse_conditioning","title":"parse_conditioning","text":"<pre><code>parse_conditioning(\n    method: Callable, *args, **kwargs\n) -&gt; Conditioning\n</code></pre> <p>Parse the execution parameters of a function into a Conditioning object.</p> <p>Inspects the signature of the function and passed arguments/keyword arguments.</p> PARAMETER DESCRIPTION <code>method</code> <p>The method</p> <p> TYPE: <code>Callable</code> </p> <code>*args</code> <p>Arguments of the method.</p> <p> DEFAULT: <code>()</code> </p> <code>**kwargs</code> <p>Keyword arguments of the method.</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Conditioning</code> <p>A Conditioning object parsed constructed based on the execution of the method.</p> RAISES DESCRIPTION <code>NotJsonableError</code> <p>when the parsed arguments cannot be serialized to json.</p> Source code in <code>src/genai_monitor/structures/conditioning_parsers/base.py</code> <pre><code>def parse_conditioning(self, method: Callable, *args, **kwargs) -&gt; Conditioning:\n    \"\"\"Parse the execution parameters of a function into a Conditioning object.\n\n    Inspects the signature of the function and passed arguments/keyword arguments.\n\n    Args:\n        method: The method\n        *args: Arguments of the method.\n        **kwargs: Keyword arguments of the method.\n\n    Returns:\n        A Conditioning object parsed constructed based on the execution of the method.\n\n    Raises:\n        NotJsonableError: when the parsed arguments cannot be serialized to json.\n    \"\"\"\n    conditioning_metadata = kwargs.pop(CONDITIONING_METADATA_FIELDNAME, None)\n    inference_params = self._get_call_params_with_defaults(method, *args, **kwargs)\n    # Get the instance from the self parameter in wrapped_inference_method\n    instance = kwargs.get(\"self\")\n\n    if instance is not None:\n        inference_params[\"__instance__\"] = instance\n\n    jsonable_value = self.parse_func_arguments(**inference_params)\n    if not is_jsonable(jsonable_value):\n        raise NotJsonableError(jsonable_value)\n\n    # Extract seeds and add to metadata\n    seed_metadata = self._extract_seeds(**inference_params)\n\n    if conditioning_metadata:\n        if not is_jsonable(conditioning_metadata):\n            raise NotJsonableError(\n                f\"Conditioning metadata not jsonable: {CONDITIONING_METADATA_FIELDNAME} = {conditioning_metadata}\"\n            )\n        if isinstance(jsonable_value, dict):\n            jsonable_value[CONDITIONING_METADATA_FIELDNAME] = conditioning_metadata\n        else:\n            jsonable_value = {\"content\": jsonable_value, \"metadata\": conditioning_metadata}  # type: ignore\n\n    conditioning_hash = get_hash_from_jsonable(jsonable_value)\n\n    return Conditioning(\n        value=jsonable_value,\n        hash=conditioning_hash,\n        value_metadata={\n            \"seeds\": seed_metadata if seed_metadata else None,\n        },\n    )\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.conditioning_parsers.base.BaseConditioningParser.parse_func_arguments","title":"parse_func_arguments  <code>abstractmethod</code>","text":"<pre><code>parse_func_arguments(*args, **kwargs) -&gt; Jsonable\n</code></pre> <p>Core function to be overwritten in subclasses.</p> <p>Parse func arguments and convert into a jsonable object - the parsing and conversion approach may vary depending on the type of func arguments.</p> PARAMETER DESCRIPTION <code>*args</code> <p>Arguments of the method.</p> <p> DEFAULT: <code>()</code> </p> <code>**kwargs</code> <p>Keyword arguments of the method.</p> <p> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>Jsonable</code> <p>Parsed parameters that can be serialized to json.</p> Source code in <code>src/genai_monitor/structures/conditioning_parsers/base.py</code> <pre><code>@abstractmethod\ndef parse_func_arguments(self, *args, **kwargs) -&gt; Jsonable:\n    \"\"\"Core function to be overwritten in subclasses.\n\n    Parse func arguments and convert into a jsonable object - the parsing and conversion approach may vary depending\n    on the type of func arguments.\n\n    Args:\n        *args: Arguments of the method.\n        **kwargs: Keyword arguments of the method.\n\n    Returns:\n        Parsed parameters that can be serialized to json.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/structures/#output-parser","title":"Output Parser","text":""},{"location":"api_reference/structures/#genai_monitor.structures.output_parsers.base.BaseModelOutputParser","title":"genai_monitor.structures.output_parsers.base.BaseModelOutputParser","text":"<p>               Bases: <code>ABC</code>, <code>Generic[T]</code></p> <p>Abstract class for converting between sample and model output types.</p>"},{"location":"api_reference/structures/#genai_monitor.structures.output_parsers.base.BaseModelOutputParser.model_output_to_bytes","title":"model_output_to_bytes  <code>abstractmethod</code>","text":"<pre><code>model_output_to_bytes(model_output: T) -&gt; bytes\n</code></pre> <p>Converts the model output to a byte representation.</p> PARAMETER DESCRIPTION <code>model_output</code> <p>The model output to convert.</p> <p> TYPE: <code>T</code> </p> RETURNS DESCRIPTION <code>bytes</code> <p>The byte representation of the model output.</p> Source code in <code>src/genai_monitor/structures/output_parsers/base.py</code> <pre><code>@abstractmethod\ndef model_output_to_bytes(self, model_output: T) -&gt; bytes:\n    \"\"\"Converts the model output to a byte representation.\n\n    Parameters:\n        model_output: The model output to convert.\n\n    Returns:\n        The byte representation of the model output.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.output_parsers.base.BaseModelOutputParser.bytes_to_model_output","title":"bytes_to_model_output  <code>abstractmethod</code>","text":"<pre><code>bytes_to_model_output(databytes: bytes) -&gt; T\n</code></pre> <p>Converts a byte representation back into model output.</p> PARAMETER DESCRIPTION <code>databytes</code> <p>The byte representation of the model output.</p> <p> TYPE: <code>bytes</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The model output reconstructed from the byte representation.</p> Source code in <code>src/genai_monitor/structures/output_parsers/base.py</code> <pre><code>@abstractmethod\ndef bytes_to_model_output(self, databytes: bytes) -&gt; T:\n    \"\"\"Converts a byte representation back into model output.\n\n    Parameters:\n        databytes: The byte representation of the model output.\n\n    Returns:\n        The model output reconstructed from the byte representation.\n    \"\"\"\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.output_parsers.base.BaseModelOutputParser.get_model_output_hash","title":"get_model_output_hash","text":"<pre><code>get_model_output_hash(data: T) -&gt; str\n</code></pre> <p>Calculates the hash value of the given data.</p> PARAMETER DESCRIPTION <code>data</code> <p>The data to calculate the hash value for.</p> <p> TYPE: <code>T</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The hash value of the data.</p> Source code in <code>src/genai_monitor/structures/output_parsers/base.py</code> <pre><code>def get_model_output_hash(self, data: T) -&gt; str:\n    \"\"\"Calculates the hash value of the given data.\n\n    Parameters:\n        data: The data to calculate the hash value for.\n\n    Returns:\n        The hash value of the data.\n    \"\"\"\n    try:\n        return self.get_base_type_hash(model_output=data)\n    except NotImplementedError:\n        logger.info(\n            \"Conversion of model output to base type not implemented, falling back to calculation of the full hash.\"\n        )\n    data_bytes = self.model_output_to_bytes(data)\n    return hashlib.sha256(data_bytes).hexdigest()\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.output_parsers.base.BaseModelOutputParser.get_base_type_hash","title":"get_base_type_hash","text":"<pre><code>get_base_type_hash(model_output: T) -&gt; str\n</code></pre> <p>Calculate the hash of the base data type stored in the model output.</p> PARAMETER DESCRIPTION <code>model_output</code> <p>The model outuput to extract the base type from.</p> <p> TYPE: <code>T</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The data in model output as one of the base supported types.</p> Source code in <code>src/genai_monitor/structures/output_parsers/base.py</code> <pre><code>def get_base_type_hash(self, model_output: T) -&gt; str:\n    \"\"\"Calculate the hash of the base data type stored in the model output.\n\n    Args:\n        model_output: The model outuput to extract the base type from.\n\n    Returns:\n        The data in model output as one of the base supported types.\n    \"\"\"\n    base_type_data = self.model_output_to_base_type(model_output=model_output)\n    return hash_base_type(data=base_type_data)\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.output_parsers.base.BaseModelOutputParser.model_output_to_base_type","title":"model_output_to_base_type","text":"<pre><code>model_output_to_base_type(model_output: T) -&gt; BaseType\n</code></pre> <p>Get the base type to calculate the hash upon.</p> PARAMETER DESCRIPTION <code>model_output</code> <p>The output of the model to extract the data from</p> <p> TYPE: <code>T</code> </p> RETURNS DESCRIPTION <code>BaseType</code> <p>One of the base data types supported in the system</p> Source code in <code>src/genai_monitor/structures/output_parsers/base.py</code> <pre><code>def model_output_to_base_type(self, model_output: T) -&gt; BaseType:\n    \"\"\"Get the base type to calculate the hash upon.\n\n    Args:\n        model_output: The output of the model to extract the data from\n\n    Returns:\n        One of the base data types supported in the system\n    \"\"\"\n    raise NotImplementedError(\"Method to extract base types from model output not specified.\")\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.output_parsers.base.BaseModelOutputParser.get_sample_from_model_output","title":"get_sample_from_model_output","text":"<pre><code>get_sample_from_model_output(model_output: T) -&gt; Sample\n</code></pre> <p>Converts the model output to a sample.</p> PARAMETER DESCRIPTION <code>model_output</code> <p>The model output to convert to a sample.</p> <p> TYPE: <code>T</code> </p> RETURNS DESCRIPTION <code>Sample</code> <p>The sample created from the model output.</p> Source code in <code>src/genai_monitor/structures/output_parsers/base.py</code> <pre><code>def get_sample_from_model_output(self, model_output: T) -&gt; Sample:\n    \"\"\"Converts the model output to a sample.\n\n    Parameters:\n        model_output: The model output to convert to a sample.\n\n    Returns:\n        The sample created from the model output.\n    \"\"\"\n    data_bytes = self.model_output_to_bytes(model_output)\n    model_output_hash = self.get_model_output_hash(model_output)\n\n    return Sample(data=data_bytes, hash=model_output_hash)\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.output_parsers.base.BaseModelOutputParser.get_model_output_from_sample","title":"get_model_output_from_sample","text":"<pre><code>get_model_output_from_sample(sample: Sample) -&gt; T\n</code></pre> <p>Converts the sample to model output.</p> PARAMETER DESCRIPTION <code>sample</code> <p>The sample to convert to model output.</p> <p> TYPE: <code>Sample</code> </p> RETURNS DESCRIPTION <code>T</code> <p>The model output created from the sample.</p> RAISES DESCRIPTION <code>ValueError</code> <p>if the data of a sample is empty</p> Source code in <code>src/genai_monitor/structures/output_parsers/base.py</code> <pre><code>def get_model_output_from_sample(self, sample: Sample) -&gt; T:\n    \"\"\"Converts the sample to model output.\n\n    Parameters:\n        sample: The sample to convert to model output.\n\n    Returns:\n        The model output created from the sample.\n\n    Raises:\n        ValueError: if the data of a sample is empty\n    \"\"\"\n    if sample.data is None:\n        raise ValueError(\"Sample data is empty.\")\n\n    return self.bytes_to_model_output(sample.data)\n</code></pre>"},{"location":"api_reference/structures/#persistency-manager","title":"Persistency Manager","text":""},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager","title":"genai_monitor.structures.persistency_manager.PersistencyManager","text":"<pre><code>PersistencyManager(path: Union[str, Path], enabled: bool)\n</code></pre> <p>Manager for saving and loading model outputs in binary format to disk.</p> Source code in <code>src/genai_monitor/structures/persistency_manager.py</code> <pre><code>def __init__(self, path: Union[str, Path], enabled: bool):  # noqa: D107, ANN204\n    self.enabled = enabled\n    path = path if path is not None else DEFAULT_PERSISTENCY_PATH\n\n    if self.enabled:\n        self.path = Path(path) if isinstance(path, str) else path\n        self.path.mkdir(parents=True, exist_ok=True)\n\n    self._configured = True\n    status = \"enabled\" if self.enabled else \"disabled\"\n    logger.info(f\"PersistencyManager configured in {status} mode.{f' Path: {self.path}' if self.enabled else ''}\")\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.path","title":"path  <code>instance-attribute</code>","text":"<pre><code>path: Path\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.enabled","title":"enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enabled: bool = enabled\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.configure","title":"configure","text":"<pre><code>configure(config: PersistencyManagerConfig)\n</code></pre> <p>Configures the persistency manager.</p> PARAMETER DESCRIPTION <code>config</code> <p>The configuration object specifying the parameters of PersistencyManager.</p> <p> TYPE: <code>PersistencyManagerConfig</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the configuration file cannot be loaded.</p> Source code in <code>src/genai_monitor/structures/persistency_manager.py</code> <pre><code>def configure(self, config: PersistencyManagerConfig):\n    \"\"\"Configures the persistency manager.\n\n    Args:\n        config: The configuration object specifying the parameters of PersistencyManager.\n\n    Raises:\n        ValueError: If the configuration file cannot be loaded.\n    \"\"\"\n    self.enabled = config.enabled\n    path = config.path if config.path is not None else DEFAULT_PERSISTENCY_PATH\n\n    if self.enabled:\n        self.path = Path(path) if isinstance(path, str) else path\n        self.path.mkdir(parents=True, exist_ok=True)\n\n    self._configured = True\n    logger.info(\n        f\"PersistencyManager configured in {'enabled' if self.enabled else 'disabled'} mode with path: {self.path}.\"\n    )\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.save_sample","title":"save_sample","text":"<pre><code>save_sample(sample: Sample)\n</code></pre> <p>Saves the sample data to a binary file.</p> PARAMETER DESCRIPTION <code>sample</code> <p>The sample to save.</p> <p> TYPE: <code>Sample</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the sample data is None.</p> <code>ValueError</code> <p>If the sample ID is None.</p> <code>ValueError</code> <p>If the PersistencyManager is disabled.</p> Source code in <code>src/genai_monitor/structures/persistency_manager.py</code> <pre><code>def save_sample(self, sample: Sample):\n    \"\"\"Saves the sample data to a binary file.\n\n    Args:\n        sample: The sample to save.\n\n    Raises:\n        ValueError: If the sample data is None.\n        ValueError: If the sample ID is None.\n        ValueError: If the PersistencyManager is disabled.\n    \"\"\"\n    if not self.is_configured():\n        raise ValueError(\"PersistencyManager has not been configured.\")\n\n    if self.enabled:\n        if sample.data is None:\n            raise ValueError(\"Sample data is None.\")\n\n        if sample.id is None:\n            raise ValueError(\"Sample has to be written to the database before saving.\")\n\n        self.save_bytes_to_disk(sample.data, f\"samples/{sample.id}.bin\")\n        logger.success(f\"Saved sample #{sample.id} to disk.\")\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.load_sample","title":"load_sample","text":"<pre><code>load_sample(sample: Sample) -&gt; bytes\n</code></pre> <p>Loads the binary file for the given sample.</p> PARAMETER DESCRIPTION <code>sample</code> <p>The sample to load.</p> <p> TYPE: <code>Sample</code> </p> RETURNS DESCRIPTION <code>bytes</code> <p>The binary data from the file.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the PersistencyManager is disabled.</p> <code>ValueError</code> <p>If the sample ID is None.</p> <code>FileNotFoundError</code> <p>If the binary file for the sample ID is not found.</p> <code>ValueError</code> <p>If the PersistencyManager has not been configured.</p> Source code in <code>src/genai_monitor/structures/persistency_manager.py</code> <pre><code>def load_sample(self, sample: Sample) -&gt; bytes:\n    \"\"\"Loads the binary file for the given sample.\n\n    Args:\n        sample: The sample to load.\n\n    Returns:\n        The binary data from the file.\n\n    Raises:\n        ValueError: If the PersistencyManager is disabled.\n        ValueError: If the sample ID is None.\n        FileNotFoundError: If the binary file for the sample ID is not found.\n        ValueError: If the PersistencyManager has not been configured.\n    \"\"\"\n    if not self.is_configured():\n        raise ValueError(\"PersistencyManager has not been configured.\")\n\n    if not self.enabled:\n        raise ValueError(\"Cannot load binary file while PersistencyManager is disabled.\")\n\n    if sample.id is None:\n        raise ValueError(\"Sample id is None.\")\n\n    bytesdata = self.load_bytes_from_disk(f\"samples/{sample.id}.bin\")\n    logger.success(f\"Loaded sample #{sample.id} from disk.\")\n    return bytesdata\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.save_bytes_to_disk","title":"save_bytes_to_disk","text":"<pre><code>save_bytes_to_disk(data: bytes, filename: str)\n</code></pre> <p>Saves the bytes to a binary file.</p> PARAMETER DESCRIPTION <code>data</code> <p>The bytes to save.</p> <p> TYPE: <code>bytes</code> </p> <code>filename</code> <p>The name of the file to save the bytes to.</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the PersistencyManager is disabled.</p> Source code in <code>src/genai_monitor/structures/persistency_manager.py</code> <pre><code>def save_bytes_to_disk(self, data: bytes, filename: str):\n    \"\"\"Saves the bytes to a binary file.\n\n    Args:\n        data: The bytes to save.\n        filename: The name of the file to save the bytes to.\n\n    Raises:\n        ValueError: If the PersistencyManager is disabled.\n    \"\"\"\n    if not self.is_configured():\n        raise ValueError(\"PersistencyManager has not been configured.\")\n\n    if self.enabled:\n        filepath = self.path / filename\n        filepath.parent.mkdir(parents=True, exist_ok=True)\n        with open(filepath, \"wb\") as file:\n            file.write(data)\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.load_bytes_from_disk","title":"load_bytes_from_disk","text":"<pre><code>load_bytes_from_disk(filename: str) -&gt; bytes\n</code></pre> <p>Loads the bytes from a binary file.</p> PARAMETER DESCRIPTION <code>filename</code> <p>The name of the file to load the bytes from.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>bytes</code> <p>The bytes from the file.</p> RAISES DESCRIPTION <code>FileNotFoundError</code> <p>If the file is not found.</p> Source code in <code>src/genai_monitor/structures/persistency_manager.py</code> <pre><code>def load_bytes_from_disk(self, filename: str) -&gt; bytes:\n    \"\"\"Loads the bytes from a binary file.\n\n    Args:\n        filename: The name of the file to load the bytes from.\n\n    Returns:\n        The bytes from the file.\n\n    Raises:\n        FileNotFoundError: If the file is not found.\n    \"\"\"\n    with open(self.path / filename, \"rb\") as file:\n        bytesdata = file.read()\n    return bytesdata\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.is_configured","title":"is_configured","text":"<pre><code>is_configured() -&gt; bool\n</code></pre> <p>Checks if the PersistencyManager has been configured.</p> RETURNS DESCRIPTION <code>bool</code> <p>Boolean indicating if the PersistencyManager has been configured.</p> Source code in <code>src/genai_monitor/structures/persistency_manager.py</code> <pre><code>def is_configured(self) -&gt; bool:\n    \"\"\"Checks if the PersistencyManager has been configured.\n\n    Returns:\n        Boolean indicating if the PersistencyManager has been configured.\n    \"\"\"\n    return self._configured\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.save_artifact","title":"save_artifact","text":"<pre><code>save_artifact(artifact: Artifact)\n</code></pre> <p>Saves the artifact data to a binary file.</p> PARAMETER DESCRIPTION <code>artifact</code> <p>The artifact to save.</p> <p> TYPE: <code>Artifact</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the artifact ID is None.</p> <code>ValueError</code> <p>If the PersistencyManager is disabled.</p> Source code in <code>src/genai_monitor/structures/persistency_manager.py</code> <pre><code>def save_artifact(self, artifact: Artifact):\n    \"\"\"Saves the artifact data to a binary file.\n\n    Args:\n        artifact: The artifact to save.\n\n    Raises:\n        ValueError: If the artifact ID is None.\n        ValueError: If the PersistencyManager is disabled.\n    \"\"\"\n    if not self.is_configured():\n        raise ValueError(\"PersistencyManager has not been configured.\")\n\n    if self.enabled:\n        if artifact.id is None:\n            raise ValueError(\"Artifact has to be written to the database before saving.\")\n\n        self.save_bytes_to_disk(json.dumps(artifact.value).encode(\"utf-8\"), f\"artifacts/{artifact.id}.bin\")\n        logger.success(f\"Saved artifact #{artifact.id} to disk.\")\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.load_artifact","title":"load_artifact","text":"<pre><code>load_artifact(artifact: Artifact) -&gt; bytes\n</code></pre> <p>Loads the binary file for the given artifact.</p> PARAMETER DESCRIPTION <code>artifact</code> <p>The artifact to load.</p> <p> TYPE: <code>Artifact</code> </p> RETURNS DESCRIPTION <code>bytes</code> <p>The binary data from the file.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the PersistencyManager is disabled.</p> <code>ValueError</code> <p>If the artifact ID is None.</p> <code>FileNotFoundError</code> <p>If the binary file for the artifact ID is not found.</p> <code>ValueError</code> <p>If the PersistencyManager has not been configured.</p> Source code in <code>src/genai_monitor/structures/persistency_manager.py</code> <pre><code>def load_artifact(self, artifact: Artifact) -&gt; bytes:\n    \"\"\"Loads the binary file for the given artifact.\n\n    Args:\n        artifact: The artifact to load.\n\n    Returns:\n        The binary data from the file.\n\n    Raises:\n        ValueError: If the PersistencyManager is disabled.\n        ValueError: If the artifact ID is None.\n        FileNotFoundError: If the binary file for the artifact ID is not found.\n        ValueError: If the PersistencyManager has not been configured.\n    \"\"\"\n    if not self.is_configured():\n        raise ValueError(\"PersistencyManager has not been configured.\")\n\n    if not self.enabled:\n        raise ValueError(\"Cannot load binary file while PersistencyManager is disabled.\")\n\n    if artifact.id is None:\n        raise ValueError(\"Artifact id is None.\")\n\n    bytesdata = self.load_bytes_from_disk(f\"artifacts/{artifact.id}.bin\")\n    logger.success(f\"Loaded artifact #{artifact.id} from disk.\")\n    return json.loads(bytesdata.decode(\"utf-8\"))\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.save_conditioning","title":"save_conditioning","text":"<pre><code>save_conditioning(conditioning: Conditioning)\n</code></pre> <p>Saves the conditioning data to a binary file.</p> PARAMETER DESCRIPTION <code>conditioning</code> <p>The conditioning to save.</p> <p> TYPE: <code>Conditioning</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If the conditioning ID is None.</p> <code>ValueError</code> <p>If the PersistencyManager is disabled.</p> Source code in <code>src/genai_monitor/structures/persistency_manager.py</code> <pre><code>def save_conditioning(self, conditioning: Conditioning):\n    \"\"\"Saves the conditioning data to a binary file.\n\n    Args:\n        conditioning: The conditioning to save.\n\n    Raises:\n        ValueError: If the conditioning ID is None.\n        ValueError: If the PersistencyManager is disabled.\n    \"\"\"\n    if not self.is_configured():\n        raise ValueError(\"PersistencyManager has not been configured.\")\n\n    if self.enabled:\n        if conditioning.id is None:\n            raise ValueError(\"Conditioning has to be written to the database before saving.\")\n\n        self.save_bytes_to_disk(\n            json.dumps(conditioning.value).encode(\"utf-8\"), f\"conditionings/{conditioning.id}.bin\"\n        )\n        logger.success(f\"Saved conditioning #{conditioning.id} to disk.\")\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.persistency_manager.PersistencyManager.load_conditioning","title":"load_conditioning","text":"<pre><code>load_conditioning(conditioning: Conditioning) -&gt; Dict\n</code></pre> <p>Loads the binary file for the given conditioning.</p> PARAMETER DESCRIPTION <code>conditioning</code> <p>The conditioning to load.</p> <p> TYPE: <code>Conditioning</code> </p> RETURNS DESCRIPTION <code>Dict</code> <p>The binary data from the file.</p> RAISES DESCRIPTION <code>ValueError</code> <p>If the PersistencyManager is disabled.</p> <code>ValueError</code> <p>If the conditioning ID is None.</p> <code>FileNotFoundError</code> <p>If the binary file for the conditioning ID is not found.</p> <code>ValueError</code> <p>If the PersistencyManager has not been configured.</p> Source code in <code>src/genai_monitor/structures/persistency_manager.py</code> <pre><code>def load_conditioning(self, conditioning: Conditioning) -&gt; Dict:\n    \"\"\"Loads the binary file for the given conditioning.\n\n    Args:\n        conditioning: The conditioning to load.\n\n    Returns:\n        The binary data from the file.\n\n    Raises:\n        ValueError: If the PersistencyManager is disabled.\n        ValueError: If the conditioning ID is None.\n        FileNotFoundError: If the binary file for the conditioning ID is not found.\n        ValueError: If the PersistencyManager has not been configured.\n    \"\"\"\n    if not self.is_configured():\n        raise ValueError(\"PersistencyManager has not been configured.\")\n\n    if not self.enabled:\n        raise ValueError(\"Cannot load binary file while PersistencyManager is disabled.\")\n\n    if conditioning.id is None:\n        raise ValueError(\"Conditioning id is None.\")\n\n    bytesdata = self.load_bytes_from_disk(f\"conditionings/{conditioning.id}.bin\")\n    logger.success(f\"Loaded conditioning #{conditioning.id} from disk.\")\n    return json.loads(bytesdata.decode(\"utf-8\"))\n</code></pre>"},{"location":"api_reference/structures/#runtime-manager","title":"Runtime Manager","text":""},{"location":"api_reference/structures/#genai_monitor.structures.runtime_manager.RuntimeManager","title":"genai_monitor.structures.runtime_manager.RuntimeManager","text":"<p>Class for managing runtime data.</p> ATTRIBUTE DESCRIPTION <code>user_id</code> <p>The user ID.</p> <p> TYPE: <code>Optional[int]</code> </p> <code>version</code> <p>The runtime version identifier.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>latest_sample</code> <p>The most recently created sample.</p> <p> TYPE: <code>Optional[Sample]</code> </p> <code>artifacts_for_next_sample</code> <p>Collection of artifacts to be associated with the next sample.</p> <p> TYPE: <code>Deque[Artifact]</code> </p>"},{"location":"api_reference/structures/#genai_monitor.structures.runtime_manager.RuntimeManager.user_id","title":"user_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>user_id: Optional[int] = None\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.runtime_manager.RuntimeManager.version","title":"version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>version: Optional[str] = None\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.runtime_manager.RuntimeManager.latest_sample","title":"latest_sample  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>latest_sample: Optional[Sample] = None\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.runtime_manager.RuntimeManager.artifacts_for_next_sample","title":"artifacts_for_next_sample  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>artifacts_for_next_sample: Deque[Artifact] = field(\n    factory=deque\n)\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.runtime_manager.RuntimeManager.set_user_id","title":"set_user_id","text":"<pre><code>set_user_id(user_id: int) -&gt; None\n</code></pre> <p>Set the user ID.</p> PARAMETER DESCRIPTION <code>user_id</code> <p>The user ID.</p> <p> TYPE: <code>int</code> </p> Source code in <code>src/genai_monitor/structures/runtime_manager.py</code> <pre><code>def set_user_id(self, user_id: int) -&gt; None:\n    \"\"\"Set the user ID.\n\n    Args:\n        user_id: The user ID.\n    \"\"\"\n    self.user_id = user_id\n</code></pre>"},{"location":"api_reference/structures/#genai_monitor.structures.runtime_manager.RuntimeManager.set_runtime_version","title":"set_runtime_version","text":"<pre><code>set_runtime_version(version: str) -&gt; None\n</code></pre> <p>Set the version.</p> PARAMETER DESCRIPTION <code>version</code> <p>The version.</p> <p> TYPE: <code>str</code> </p> Source code in <code>src/genai_monitor/structures/runtime_manager.py</code> <pre><code>def set_runtime_version(self, version: str) -&gt; None:\n    \"\"\"Set the version.\n\n    Args:\n        version: The version.\n    \"\"\"\n    self.version = version\n</code></pre>"},{"location":"api_reference/utils/","title":"Utils","text":""},{"location":"api_reference/utils/#auto-mode-configuration","title":"Auto mode configuration","text":""},{"location":"api_reference/utils/#genai_monitor.utils.auto_mode_configuration.load_config","title":"genai_monitor.utils.auto_mode_configuration.load_config","text":"<pre><code>load_config(\n    db_url: str,\n    default_settings: Dict[\n        str, dict[str, str]\n    ] = DEFAULT_SETTINGS,\n) -&gt; Config\n</code></pre> <p>Load configuration from database.</p> PARAMETER DESCRIPTION <code>db_url</code> <p>The database URL.</p> <p> TYPE: <code>str</code> </p> <code>default_settings</code> <p>The default settings to use if no configuration is found.</p> <p> TYPE: <code>Dict[str, dict[str, str]]</code> DEFAULT: <code>DEFAULT_SETTINGS</code> </p> RETURNS DESCRIPTION <code>Config</code> <p>The configuration as a dictionary.</p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If the configuration could not be loaded.</p> Source code in <code>src/genai_monitor/utils/auto_mode_configuration.py</code> <pre><code>def load_config(db_url: str, default_settings: Dict[str, dict[str, str]] = DEFAULT_SETTINGS) -&gt; Config:\n    \"\"\"Load configuration from database.\n\n    Args:\n        db_url: The database URL.\n        default_settings: The default settings to use if no configuration is found.\n\n    Returns:\n        The configuration as a dictionary.\n\n    Raises:\n        RuntimeError: If the configuration could not be loaded.\n    \"\"\"\n    logger.info(f\"Using database at: {db_url}\")\n\n    # Initialize database with the url\n    session_manager = init_db(database_url=db_url)\n\n    try:\n        with session_manager.session_scope() as session:\n            # Initialize default configuration if needed\n            _init_default_config(session, default_settings)\n\n            # Load configuration, preferring non-default values over defaults\n            config_entries = (\n                session.query(ConfigurationTable).order_by(ConfigurationTable.is_default).all()  # Non-defaults first\n            )\n\n            # Build config dict, letting non-default values override defaults\n            settings_dict = {}\n            for entry in config_entries:\n                if entry.key not in settings_dict:  # Only set if not already set by a non-default\n                    settings_dict[entry.key] = entry.value\n\n            return Config(\n                persistency={  # type: ignore\n                    \"enabled\": settings_dict[\"persistency.enabled\"].lower() == \"true\",\n                    \"path\": settings_dict[\"persistency.path\"],\n                },\n                db={\"url\": settings_dict[\"db.url\"]},  # type: ignore\n                version=settings_dict[\"version\"],\n            )\n\n    except SQLAlchemyError as e:\n        logger.error(f\"Failed to load configuration from database: {e}\")\n        raise RuntimeError(\"Failed to load configuration\") from e\n</code></pre>"},{"location":"api_reference/utils/#data-hashing","title":"Data hashing","text":""},{"location":"api_reference/utils/#genai_monitor.utils.model_hashing.default_model_hashing_function","title":"genai_monitor.utils.model_hashing.default_model_hashing_function","text":"<pre><code>default_model_hashing_function(\n    model: Any,\n) -&gt; str | Literal[UNKNOWN_MODEL_HASH]\n</code></pre> <p>Default model hashing function.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to hash.</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>str | Literal[UNKNOWN_MODEL_HASH]</code> <p>str | Literal[UNKNOWN_MODEL_HASH]: The hash of the model.</p> Source code in <code>src/genai_monitor/utils/model_hashing.py</code> <pre><code>def default_model_hashing_function(model: Any) -&gt; str | Literal[UNKNOWN_MODEL_HASH]:  # type: ignore\n    \"\"\"Default model hashing function.\n\n    Args:\n        model: The model to hash.\n\n    Returns:\n        str | Literal[UNKNOWN_MODEL_HASH]: The hash of the model.\n    \"\"\"\n    try:\n        return get_component_hash(model)\n    except Exception as e:\n        logger.error(f\"Failed to hash model: {e}\")\n        return UNKNOWN_MODEL_HASH\n</code></pre>"},{"location":"api_reference/utils/#user-registration","title":"User registration","text":""},{"location":"api_reference/utils/#genai_monitor.utils.user_registration.register_user","title":"genai_monitor.utils.user_registration.register_user","text":"<pre><code>register_user(\n    db_manager: DBManager, runtime_manager: RuntimeManager\n)\n</code></pre> <p>Register a new user if not already registered.</p> PARAMETER DESCRIPTION <code>db_manager</code> <p>The database manager.</p> <p> TYPE: <code>DBManager</code> </p> <code>runtime_manager</code> <p>The runtime manager.</p> <p> TYPE: <code>RuntimeManager</code> </p> Source code in <code>src/genai_monitor/utils/user_registration.py</code> <pre><code>def register_user(db_manager: DBManager, runtime_manager: RuntimeManager):\n    \"\"\"Register a new user if not already registered.\n\n    Args:\n        db_manager: The database manager.\n        runtime_manager: The runtime manager.\n    \"\"\"\n    user_hash = generate_user_hash()\n\n    existing_user = db_manager.search(\n        UserTable,\n        {\"hash\": user_hash},\n    )\n\n    if existing_user:\n        runtime_manager.set_user_id(existing_user[0].id)\n        logger.info(f\"User {existing_user[0].name} found in the database.\")\n        return\n\n    logger.info(\"User not found in the database. Registering new user.\")\n    username = getpass.getuser()\n    user = User(name=username, hash=user_hash)\n    user = db_manager.save(instance=user.to_orm())\n    runtime_manager.set_user_id(user.id)\n    logger.success(f\"User {user.name} registered successfully.\")\n</code></pre>"},{"location":"how_to/artifact_tracking/","title":"Artifact Tracking","text":""},{"location":"how_to/artifact_tracking/#overview","title":"Overview","text":"<p>Artifact tracking is a powerful feature that allows you to associate additional information with your generative AI model inference outputs. It enables you to trace relationships between model inputs, outputs, and intermediate artifacts throughout the inference process.</p>"},{"location":"how_to/artifact_tracking/#key-concepts","title":"Key Concepts","text":"<p>The artifact tracking system builds upon the observable function registration framework and extends it with two primary capabilities:</p> <ol> <li>Forward Tracking: Associate artifacts created before model inference with upcoming outputs</li> <li>Backward Tracking: Associate artifacts with the most recently created inference outputs</li> </ol>"},{"location":"how_to/artifact_tracking/#registration-api","title":"Registration API","text":""},{"location":"how_to/artifact_tracking/#forward-artifact-registration","title":"Forward Artifact Registration","text":"<p>To establish a forward tracking relationship, use <code>register_forward_artifact</code>:</p> <pre><code>from genai_monitor.registration import register_forward_artifact\n\ndef get_timestamp():\n    return {\"time\": sys.time}\n\nregister_forward_artifact(get_timestamp())\n\nget_timestamp() # Artifact is created, awaits sample generation\n</code></pre>"},{"location":"how_to/artifact_tracking/#backward-artifact-registration","title":"Backward Artifact Registration","text":"<p>To establish a backward tracking relationship, use <code>register_backward_artifact</code>:</p> <pre><code>from genai_monitor.registration import register_backward_artifact\n\ndef get_timestamp():\n    return {\"time\": sys.time}\n\nregister_backward_artifact(get_timestamp())\n\n# Sample generation here\n\nget_timestamp() # added relationship to above sample\n</code></pre> <p>This explicitly records which inputs, parameters, and contexts contributed to your model's outputs.</p>"},{"location":"how_to/cached_instances/","title":"Cached Instances","text":""},{"location":"how_to/cached_instances/#overview","title":"Overview","text":"<p>GenAI Monitor by default stores only one copy of the same inference (identical input arguments) to optimize storage and prevent redundant API calls. However, there are many scenarios where you might want to preserve multiple unique outputs for the same input, such as:</p> <ul> <li>Exploring the variety of possible responses with non-deterministic generation</li> <li>A/B testing different outputs for the same prompt</li> <li>Building datasets with diverse completions</li> <li>Testing model consistency across multiple runs</li> </ul>"},{"location":"how_to/cached_instances/#how-it-works","title":"How It Works","text":""},{"location":"how_to/cached_instances/#storage-phase","title":"Storage Phase","text":"<p>When <code>max_unique_instances</code> is set to a value greater than 1:</p> <ol> <li>For each new invocation with identical inputs, GenAI Monitor checks if the maximum number of unique instances has been reached</li> <li>If the limit hasn't been reached, the function executes normally and the new output is stored</li> <li>Once the limit is reached, GenAI Monitor switches to retrieval mode</li> </ol>"},{"location":"how_to/cached_instances/#retrieval-phase","title":"Retrieval Phase","text":"<p>When the maximum number of unique instances has been stored: 1. GenAI Monitor selects one of the previously stored outputs using round-robin selection 2. The selected output is returned without re-invoking the function 3. Each subsequent call with identical inputs receives the next stored output in sequence</p>"},{"location":"how_to/cached_instances/#configuring-multiple-unique-instances","title":"Configuring Multiple Unique Instances","text":"<p>GenAI Monitor provides registration API that supports the <code>max_unique_instances</code> parameter:</p> <pre><code>from copy import deepcopy\nimport io\nfrom torch import nn\nimport torch\n\nfrom genai_monitor.registration.api import register_class\nfrom genai_monitor.utils.data_hashing import Jsonable\nfrom genai_monitor.utils.model_hashing import default_model_hashing_function\n\nimport genai_monitor.auto\n\nclass DummyPytorchModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc = nn.Linear(10, 5)\n\n    def forward(self, x):\n        return self.fc(x)\n\ndef model_output_to_bytes(model_output: torch.Tensor) -&gt; bytes:\n    buffer = io.BytesIO()\n    torch.save(model_output, buffer)\n    return buffer.getvalue()\n\ndef bytes_to_model_output(databytes: bytes) -&gt; torch.Tensor:\n    buffer = io.BytesIO(databytes)\n    return torch.load(buffer, weights_only=True)\n\ndef parse_func_arguments(**kwargs) -&gt; Jsonable:\n    parsed_arguments = deepcopy(kwargs)\n    for key, value in parsed_arguments.items():\n        if isinstance(value, torch.Tensor):\n            parsed_arguments[key] = value.tolist()\n    return parsed_arguments\n\n\nregister_class(\n    cls=DummyPytorchModel,\n    inference_methods=[\"forward\"],\n    model_output_to_bytes=model_output_to_bytes,\n    bytes_to_model_output=bytes_to_model_output,\n    parse_inference_method_arguments=parse_func_arguments,\n    model_hashing_function=default_model_hashing_function,\n    max_unique_instances=3\n)\n\nmodel_instance = DummyPytorchModel()\nx = torch.randn(1, 10)\n\n# Below model outputs will be generated.\ny1 = model_instance(x)\ny2 = model_instance(x)\ny3 = model_instance(x)\n\n# Since `max_unique_instaces`=3, next generations will be retrieved from GenAI Monitor.\ny4 = model_instance(x) # same as y1\ny5 = model_instance(x) # same as y2\ny6 = model_instance(x) # same as y3\n</code></pre>"},{"location":"how_to/custom_registration/","title":"Custom Registration for GenAI Monitor","text":"<p>The GenAI Monitor registration API allows you to extend monitoring capabilities to any function or class of your choice, even if they're not automatically supported by the built-in integrations.</p>"},{"location":"how_to/custom_registration/#how-custom-registration-works","title":"How Custom Registration Works","text":"<p>When you register a function or class method:</p> <ol> <li>GenAI Monitor intercepts calls to the registered function/method</li> <li>Input arguments are captured and hashed for lookup</li> <li>If identical inputs were previously processed, results are retrieved from the database</li> <li>If this is a new input, the original function executes and results are stored</li> <li>All of this happens transparently to your application code</li> </ol>"},{"location":"how_to/custom_registration/#key-registration-parameters","title":"Key Registration Parameters","text":"<ul> <li><code>model_output_to_bytes</code>: Converts any model output to <code>bytes</code> type</li> <li><code>bytes_to_model_output</code>: Converts stored <code>bytes</code> object back to the original output format</li> <li><code>parse_inference_method_arguments</code>: Parses call arguments into a jsonable format for caching and lookup</li> <li><code>sample_fields_to_parsing_methods</code>: Maps input fields to parsing functions (# TODO: is this still relevant?)</li> <li><code>max_unique_instances</code>: Controls how many unique outputs to store per input (# add section on this + add link here)</li> </ul> <p>This flexible registration system allows you to bring GenAI Monitor's observability to any AI component in your system, whether it's a third-party library or your own custom implementation.</p>"},{"location":"how_to/custom_registration/#registering-custom-classes","title":"Registering Custom Classes","text":"<p>Use <code>register_class</code> to monitor inference methods of any Python class:</p> <pre><code>from copy import deepcopy\nimport io\nfrom torch import nn\nimport torch\n\nfrom genai_monitor.registration.api import register_class\nfrom genai_monitor.utils.data_hashing import Jsonable\nfrom genai_monitor.utils.model_hashing import default_model_hashing_function\n\nimport genai_monitor.auto\n\nclass DummyPytorchModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Potentially large PyTorch model...\n        self.fc = nn.Linear(10, 5)\n\n    def forward(self, x):\n        return self.fc(x)\n\ndef model_output_to_bytes(model_output: torch.Tensor) -&gt; bytes:\n    buffer = io.BytesIO()\n    torch.save(model_output, buffer)\n    return buffer.getvalue()\n\ndef bytes_to_model_output(databytes: bytes) -&gt; torch.Tensor:\n    buffer = io.BytesIO(databytes)\n    return torch.load(buffer, weights_only=True)\n\ndef parse_func_arguments(**kwargs) -&gt; Jsonable:\n    parsed_arguments = deepcopy(kwargs)\n    for key, value in parsed_arguments.items():\n        if isinstance(value, torch.Tensor):\n            parsed_arguments[key] = value.tolist()\n    return parsed_arguments\n\n\nregister_class(\n    cls=DummyPytorchModel,\n    inference_methods=[\"forward\"],\n    model_output_to_bytes=model_output_to_bytes,\n    bytes_to_model_output=bytes_to_model_output,\n    parse_inference_method_arguments=parse_func_arguments,\n    model_hashing_function=default_model_hashing_function,\n)\n\nmodel_instance = DummyPytorchModel()\nx = torch.randn(1, 10)\n\n# First model inference is generated.\nfirst_inference = model_instance(x)\n\n# When model is called with the same input parameters, the output is retrieved from GenAI Monitor.\nsecond_inference = model_instance(x)\n</code></pre>"},{"location":"how_to/db_setup/","title":"Database and Persistence Configuration","text":""},{"location":"how_to/db_setup/#overview","title":"Overview","text":"<p>GenAI Monitor stores both structured data (in a SQLite database) and unstructured data (model inputs/outputs and other artifacts) on disk. This documentation explains how to configure these storage mechanisms using environment variables.</p>"},{"location":"how_to/db_setup/#configuration-options","title":"Configuration Options","text":"<p>GenAI Monitor uses two main environment variables to configure data storage:</p> <ol> <li><code>GENAI_MONITOR_DB_URL</code>: Defines the SQLite database location</li> <li><code>GENAI_MONITOR_PERSISTENCY_PATH</code>: Specifies the directory where unstructured data is stored</li> </ol>"},{"location":"how_to/db_setup/#setting-up-the-database","title":"Setting Up the Database","text":""},{"location":"how_to/db_setup/#sqlite-database-url","title":"SQLite Database URL","text":"<p>The <code>GENAI_MONITOR_DB_URL</code> environment variable controls where your SQLite database is stored. This database contains metadata about model calls, relationships between artifacts, and other structured information.</p> <pre><code># Example: Store the database in a specific location\nexport GENAI_MONITOR_DB_URL=\"sqlite:///path/to/your/genai_monitor.db\"\n\n# Default: If not specified, a default location (current working directory) will be used\n</code></pre>"},{"location":"how_to/db_setup/#persistence-path-for-unstructured-data","title":"Persistence Path for Unstructured Data","text":"<p>The <code>GENAI_MONITOR_PERSISTENCY_PATH</code> environment variable specifies the absolute path to a directory where all large objects (like model inputs, outputs, embeddings, and other artifacts) will be stored. This separation allows for efficient database operations while still preserving all valuable data.</p> <pre><code># Example: Store persistent objects in a specific directory\nexport GENAI_MONITOR_PERSISTENCY_PATH=\"/path/to/your/persistency/directory\"\n</code></pre>"},{"location":"how_to/db_setup/#initialization-process","title":"Initialization Process","text":"<p>When you first import GenAI Monitor, the system performs several setup operations:</p> <ol> <li>The database is initialized according to <code>GENAI_MONITOR_DB_URL</code> (or using the default location if not specified)</li> <li>The persistence path from <code>GENAI_MONITOR_PERSISTENCY_PATH</code> is recorded in the database</li> <li>In subsequent runs, the persistence path is read from the database, ensuring consistency</li> </ol> <pre><code># First import triggers initialization\nimport genai_monitor.auto\n\n# Now GenAI Monitor is initialized with your configured storage locations\n</code></pre>"},{"location":"how_to/model_metadata/","title":"Model Metadata","text":""},{"location":"how_to/model_metadata/#overview","title":"Overview","text":"<p>When working with generative AI models, it's often valuable to associate additional context or metadata with your model calls. The GenAI Monitor system provides a simple way to attach arbitrary metadata to your model calls using the <code>genai_monitor_metadata</code> parameter.</p>"},{"location":"how_to/model_metadata/#adding-metadata-to-model-calls","title":"Adding Metadata to Model Calls","text":""},{"location":"how_to/model_metadata/#basic-usage","title":"Basic Usage","text":"<p>To add metadata to your model call, simply include the <code>genai_monitor_metadata</code> parameter as part of your keyword arguments:</p> <pre><code>response = model.generate(\n    prompt=\"Summarize the latest research on large language models.\",\n    max_tokens=500,\n    temperature=0.7,\n    genai_monitor_metadata={\n        \"request_id\": \"12345\",\n        \"user_id\": \"user_789\",\n        \"application\": \"research_assistant\"\n    }\n)\n</code></pre> <p>The metadata will be automatically captured and associated with both the request and response, without affecting the model's generation behavior.</p>"},{"location":"how_to/model_metadata/#metadata-structure","title":"Metadata Structure","text":"<p>The <code>genai_monitor_metadata</code> parameter accepts any JSON-serializable dictionary. You can include any information relevant to your application:</p> <pre><code>genai_monitor_metadata={\n    # Request context\n    \"user_id\": \"user_123\",\n    \"session_id\": \"abc-xyz-789\",\n    \"timestamp\": \"2023-08-15T14:32:17Z\",\n\n    # Business context\n    \"project\": \"customer_support\",\n    \"priority\": \"high\",\n    \"category\": \"technical_issue\",\n\n    # Technical context\n    \"client_version\": \"2.1.3\",\n    \"experiment_id\": \"prompt-variation-b\",\n    \"retry_count\": 0\n}\n</code></pre>"},{"location":"quickstart/auto_mode/","title":"Quickstart Guide for GenAI Monitor","text":"<p>GenAI Monitor provides automatic observability for your GenAI applications with zero code changes. Follow this guide to get started with minimal effort.</p>"},{"location":"quickstart/auto_mode/#installation","title":"Installation","text":"<p>Install the base package with support for your preferred AI framework:</p> <pre><code># Choose one or more providers based on your needs\npip install \"genai-monitor[openai]\"     # For OpenAI API\npip install \"genai-monitor[transformers]\"  # For Hugging Face Transformers\npip install \"genai-monitor[diffusers]\"  # For Hugging Face Diffusers\npip install \"genai-monitor[litellm]\"    # For LiteLLM\n\n# Or install with all providers\npip install \"genai-monitor[all]\"\n</code></pre>"},{"location":"quickstart/auto_mode/#implicit-monitoring-zero-code-changes","title":"Implicit Monitoring (Zero-Code Changes)","text":"<p>Simply import the auto module at the beginning of your application:</p> <pre><code># Import this first to enable automatic monitoring\nimport genai_monitor.auto\n\n# Then use your AI libraries as usual - no changes needed!\n</code></pre>"},{"location":"quickstart/auto_mode/#example-with-openai","title":"Example with OpenAI","text":"<pre><code>import os\nimport genai_monitor.auto  # This enables monitoring automatically\nfrom openai import OpenAI\n\n# Your regular OpenAI code\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\nquestion = \"What is the capital of France?\"\n\n# First call - sent to OpenAI and cached in database\nresponse = client.chat.completions.create(\n    messages=[{\"role\": \"user\", \"content\": question}],\n    model=\"gpt-3.5-turbo\",\n)\nprint(response.choices[0].message.content)\n\n# Second call with same parameters - retrieved from database, no API call made!\nresponse = client.chat.completions.create(\n    messages=[{\"role\": \"user\", \"content\": question}],\n    model=\"gpt-3.5-turbo\",\n)\nprint(response.choices[0].message.content)\n</code></pre>"},{"location":"quickstart/auto_mode/#example-with-transformers","title":"Example with Transformers","text":"<pre><code>import genai_monitor.auto  # This enables monitoring automatically\nfrom transformers import pipeline\n\n# Your regular transformers code\ngenerator = pipeline('text-generation', model='gpt2')\n\n# First call - runs model and caches result\nresult = generator(\"Hello, I'm a language model\", max_length=30)\nprint(result[0]['generated_text'])\n\n# Second call with same parameters - retrieved from database, no model inference!\nresult = generator(\"Hello, I'm a language model\", max_length=30)\nprint(result[0]['generated_text'])\n</code></pre>"},{"location":"quickstart/auto_mode/#how-it-works","title":"How It Works","text":"<p>GenAI Monitor automatically:</p> <ol> <li>Intercepts calls to supported AI frameworks</li> <li>Stores inputs and outputs in a local database</li> <li>Returns cached results for identical calls</li> <li>Provides this functionality with zero application code changes</li> </ol> <p>This approach dramatically reduces:</p> <ul> <li>API costs by eliminating duplicate calls</li> <li>Latency by skipping remote API calls for repeated queries</li> <li>Compute resources by caching expensive model inferences</li> </ul>"},{"location":"quickstart/auto_mode/#next-steps","title":"Next Steps","text":"<ul> <li>See how to use explicit registration for unsupported frameworks</li> <li>Add artifact tracking to your model calls</li> <li>Add metadata to your model calls</li> </ul>"}]}